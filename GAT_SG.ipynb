{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "hV6QpbJXMOZ1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV6QpbJXMOZ1",
        "outputId": "7f024d46-ad2e-4a71-9fc5-d23a83d403d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  all.zip\n",
            "  inflating: .DS_Store               \n",
            "   creating: .git/\n",
            "  inflating: .git/config             \n",
            "   creating: .git/objects/\n",
            "   creating: .git/objects/pack/\n",
            "  inflating: .git/objects/pack/pack-2ca7792152d971f87066cb44277bc2209794d002.pack  \n",
            "  inflating: .git/objects/pack/pack-2ca7792152d971f87066cb44277bc2209794d002.idx  \n",
            "   creating: .git/objects/info/\n",
            " extracting: .git/HEAD               \n",
            "   creating: .git/info/\n",
            "  inflating: .git/info/exclude       \n",
            "   creating: .git/logs/\n",
            "  inflating: .git/logs/HEAD          \n",
            "   creating: .git/logs/refs/\n",
            "   creating: .git/logs/refs/heads/\n",
            "  inflating: .git/logs/refs/heads/main  \n",
            "   creating: .git/logs/refs/remotes/\n",
            "   creating: .git/logs/refs/remotes/origin/\n",
            "  inflating: .git/logs/refs/remotes/origin/HEAD  \n",
            "  inflating: .git/description        \n",
            "   creating: .git/hooks/\n",
            "  inflating: .git/hooks/commit-msg.sample  \n",
            "  inflating: .git/hooks/pre-rebase.sample  \n",
            "  inflating: .git/hooks/pre-commit.sample  \n",
            "  inflating: .git/hooks/applypatch-msg.sample  \n",
            "  inflating: .git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: .git/hooks/pre-receive.sample  \n",
            "  inflating: .git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: .git/hooks/post-update.sample  \n",
            "  inflating: .git/hooks/pre-merge-commit.sample  \n",
            "  inflating: .git/hooks/pre-applypatch.sample  \n",
            "  inflating: .git/hooks/pre-push.sample  \n",
            "  inflating: .git/hooks/update.sample  \n",
            "  inflating: .git/hooks/push-to-checkout.sample  \n",
            "   creating: .git/refs/\n",
            "   creating: .git/refs/heads/\n",
            " extracting: .git/refs/heads/main    \n",
            "   creating: .git/refs/tags/\n",
            "   creating: .git/refs/remotes/\n",
            "   creating: .git/refs/remotes/origin/\n",
            " extracting: .git/refs/remotes/origin/HEAD  \n",
            "  inflating: .git/index              \n",
            "  inflating: .git/packed-refs        \n",
            "   creating: .github/\n",
            " extracting: .github/FUNDING.yml     \n",
            "  inflating: .gitignore              \n",
            "  inflating: LICENCE                 \n",
            "  inflating: README.md               \n",
            "  inflating: The Annotated GAT (Cora).ipynb  \n",
            "  inflating: The Annotated GAT (PPI).ipynb  \n",
            "   creating: data/\n",
            "   creating: data/readme_pics/\n",
            "  inflating: data/readme_pics/cora_degree_statistics.PNG  \n",
            "   creating: data/readme_pics/entropy_histograms/\n",
            "  inflating: data/readme_pics/entropy_histograms/layer_1_head_0.jpg  \n",
            "  inflating: data/readme_pics/entropy_histograms/layer_0_head_0.jpg  \n",
            "  inflating: data/readme_pics/ppi_graph_jupyter.PNG  \n",
            "  inflating: data/readme_pics/cora_graph.PNG  \n",
            "  inflating: data/readme_pics/protein.png  \n",
            "  inflating: data/readme_pics/val_acc.PNG  \n",
            "  inflating: data/readme_pics/attention2.jpg  \n",
            "  inflating: data/readme_pics/attention3.jpg  \n",
            "   creating: data/readme_pics/entropy_histograms_ppi/\n",
            "  inflating: data/readme_pics/entropy_histograms_ppi/layer_0_head_0.jpg  \n",
            "  inflating: data/readme_pics/attention1.jpg  \n",
            "   creating: data/readme_pics/neighborhood_attention_ppi/\n",
            "  inflating: data/readme_pics/neighborhood_attention_ppi/4.jpg  \n",
            "  inflating: data/readme_pics/neighborhood_attention_ppi/2.jpg  \n",
            "  inflating: data/readme_pics/neighborhood_attention_ppi/3.jpg  \n",
            "  inflating: data/readme_pics/neighborhood_attention_ppi/1.jpg  \n",
            "  inflating: data/readme_pics/attention4.jpg  \n",
            "  inflating: data/readme_pics/t-sne.PNG  \n",
            "  inflating: data/readme_pics/kk_layout.jpg  \n",
            "  inflating: data/readme_pics/cora_graph_jupyter.PNG  \n",
            "  inflating: data/readme_pics/GAT_schematic.PNG  \n",
            "  inflating: data/readme_pics/val_loss.PNG  \n",
            "   creating: data/cora/\n",
            "  inflating: data/cora/node_labels.npy  \n",
            "  inflating: data/cora/adjacency_list.dict  \n",
            "  inflating: data/cora/node_features.csr  \n",
            "  inflating: environment.yml         \n",
            "   creating: models/\n",
            "   creating: models/binaries/\n",
            "  inflating: models/binaries/gat_000000.pth  \n",
            "  inflating: models/binaries/gat_PPI_000000.pth  \n",
            "   creating: models/definitions/\n",
            "  inflating: models/definitions/GAT.py  \n",
            "  inflating: playground.py           \n",
            "  inflating: requirements.txt        \n",
            "  inflating: training_script_cora.py  \n",
            "  inflating: training_script_ppi.py  \n",
            "   creating: utils/\n",
            "  inflating: utils/data_loading.py   \n",
            "  inflating: utils/constants.py      \n",
            "  inflating: utils/dataset.py        \n",
            "  inflating: utils/visualizations.py  \n",
            "  inflating: utils/utils.py          \n",
            "  inflating: wordnet_doctor.png      \n"
          ]
        }
      ],
      "source": [
        "!unzip all.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "Ogw7X5GFPfSA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogw7X5GFPfSA",
        "outputId": "bd7cd60c-d125-450f-89b7-878fbd6e2b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Feb 15 10:41:01 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "yVgTzV6yNoE2",
      "metadata": {
        "id": "yVgTzV6yNoE2"
      },
      "outputs": [],
      "source": [
        "#!pip install torch==1.10.0+cu111 torchvision==0.11.1+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "vBjR1V427KtX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBjR1V427KtX",
        "outputId": "91b95ad2-76cc-481c-eaa3-89efa1f13d51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.10.0+cu111\n",
            "11.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "zZLcpIWvNDSb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZLcpIWvNDSb",
        "outputId": "5e3f5d26-90cf-4800-9e31-108e47f6e079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Collecting GitPython\n",
            "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (2.7.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (2.6.3)\n",
            "Collecting igraph\n",
            "  Downloading igraph-0.9.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 39.2 MB/s \n",
            "\u001b[?25hCollecting pycairo\n",
            "  Downloading pycairo-1.20.1.tar.gz (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 34.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cairocffi\n",
            "  Downloading cairocffi-1.3.0.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 4)) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython->-r requirements.txt (line 5)) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 6)) (5.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 6)) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 6)) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 6)) (7.6.5)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 6)) (4.10.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->-r requirements.txt (line 6)) (5.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.17.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.43.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 10)) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 10)) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 10)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 10)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 10)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 10)) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 10)) (3.2.0)\n",
            "Collecting texttable>=1.6.2\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi->-r requirements.txt (line 14)) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi->-r requirements.txt (line 14)) (2.21)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 6)) (5.5.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 6)) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 6)) (5.3.5)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 6)) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->-r requirements.txt (line 6)) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->-r requirements.txt (line 6)) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->-r requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->-r requirements.txt (line 6)) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->-r requirements.txt (line 6)) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->-r requirements.txt (line 6)) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 6)) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 6)) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 6)) (3.5.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 6)) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 6)) (4.9.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 6)) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 6)) (5.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 6)) (21.4.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 6)) (0.13.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 6)) (1.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->-r requirements.txt (line 6)) (2.11.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->-r requirements.txt (line 6)) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->-r requirements.txt (line 6)) (2.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (4.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 6)) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 6)) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 6)) (21.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 6)) (2.0.1)\n",
            "Building wheels for collected packages: pycairo, cairocffi\n",
            "  Building wheel for pycairo (PEP 517) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pycairo\u001b[0m\n",
            "  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cairocffi: filename=cairocffi-1.3.0-py3-none-any.whl size=89668 sha256=415965dd36c56ffe8104c6435d537004caf3cbc474489b2069c7e0c8e413a27e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/e1/5c8a9692a27f639a07c949044bec943f26c81cd53d3805319f\n",
            "Successfully built cairocffi\n",
            "Failed to build pycairo\n",
            "\u001b[31mERROR: Could not build wheels for pycairo which use PEP 517 and cannot be installed directly\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "L6LcpR06R-NY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6LcpR06R-NY",
        "outputId": "c05b21e3-a206-4041-e725-12e8ab6e7d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libcairo2 is already the newest version (1.15.10-2ubuntu0.1).\n",
            "libcairo2 set to manually installed.\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  gir1.2-freedesktop gobject-introspection libffi-dev python3-mako\n",
            "  python3-markupsafe\n",
            "Suggested packages:\n",
            "  libgirepository1.0-doc python3-beaker python-mako-doc\n",
            "The following NEW packages will be installed:\n",
            "  gir1.2-freedesktop gobject-introspection libffi-dev libgirepository1.0-dev\n",
            "  python3-cairo python3-mako python3-markupsafe\n",
            "0 upgraded, 7 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 1,247 kB of archives.\n",
            "After this operation, 10.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-freedesktop amd64 1.56.1-1 [9,080 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-markupsafe amd64 1.0-1build1 [13.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-mako all 1.0.7+ds1-1 [59.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 gobject-introspection amd64 1.56.1-1 [270 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libffi-dev amd64 3.2.1-8 [156 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgirepository1.0-dev amd64 1.56.1-1 [683 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cairo amd64 1.16.2-1 [56.1 kB]\n",
            "Fetched 1,247 kB in 1s (1,247 kB/s)\n",
            "Selecting previously unselected package gir1.2-freedesktop:amd64.\n",
            "(Reading database ... 155113 files and directories currently installed.)\n",
            "Preparing to unpack .../0-gir1.2-freedesktop_1.56.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-freedesktop:amd64 (1.56.1-1) ...\n",
            "Selecting previously unselected package python3-markupsafe.\n",
            "Preparing to unpack .../1-python3-markupsafe_1.0-1build1_amd64.deb ...\n",
            "Unpacking python3-markupsafe (1.0-1build1) ...\n",
            "Selecting previously unselected package python3-mako.\n",
            "Preparing to unpack .../2-python3-mako_1.0.7+ds1-1_all.deb ...\n",
            "Unpacking python3-mako (1.0.7+ds1-1) ...\n",
            "Selecting previously unselected package gobject-introspection.\n",
            "Preparing to unpack .../3-gobject-introspection_1.56.1-1_amd64.deb ...\n",
            "Unpacking gobject-introspection (1.56.1-1) ...\n",
            "Selecting previously unselected package libffi-dev:amd64.\n",
            "Preparing to unpack .../4-libffi-dev_3.2.1-8_amd64.deb ...\n",
            "Unpacking libffi-dev:amd64 (3.2.1-8) ...\n",
            "Selecting previously unselected package libgirepository1.0-dev:amd64.\n",
            "Preparing to unpack .../5-libgirepository1.0-dev_1.56.1-1_amd64.deb ...\n",
            "Unpacking libgirepository1.0-dev:amd64 (1.56.1-1) ...\n",
            "Selecting previously unselected package python3-cairo:amd64.\n",
            "Preparing to unpack .../6-python3-cairo_1.16.2-1_amd64.deb ...\n",
            "Unpacking python3-cairo:amd64 (1.16.2-1) ...\n",
            "Setting up gir1.2-freedesktop:amd64 (1.56.1-1) ...\n",
            "Setting up libffi-dev:amd64 (3.2.1-8) ...\n",
            "Setting up python3-markupsafe (1.0-1build1) ...\n",
            "Setting up python3-cairo:amd64 (1.16.2-1) ...\n",
            "Setting up python3-mako (1.0.7+ds1-1) ...\n",
            "Setting up gobject-introspection (1.56.1-1) ...\n",
            "Setting up libgirepository1.0-dev:amd64 (1.56.1-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt install libgirepository1.0-dev python3-cairo libcairo2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3qWRt8q7Rw4i",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qWRt8q7Rw4i",
        "outputId": "1a4dfbc4-1b67-42ff-9558-06229bdb42d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycairo in /usr/lib/python3/dist-packages (1.16.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycairo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "Rv1QVVwASgY-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv1QVVwASgY-",
        "outputId": "a2814333-da0e-474c-f674-bc743ba7e1c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting igraph\n",
            "  Using cached igraph-0.9.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "Collecting texttable>=1.6.2\n",
            "  Using cached texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, igraph\n",
            "Successfully installed igraph-0.9.9 texttable-1.6.4\n"
          ]
        }
      ],
      "source": [
        "!pip install igraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "wB-Vj_CvV1hU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB-Vj_CvV1hU",
        "outputId": "a8f24fac-6554-4b99-e903-ff3932333f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: igraph in /usr/local/lib/python3.7/dist-packages (0.9.9)\n",
            "Requirement already satisfied: pycairo in /usr/lib/python3/dist-packages (1.16.2)\n",
            "Collecting cairocffi\n",
            "  Using cached cairocffi-1.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from igraph) (1.6.4)\n",
            "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.21)\n",
            "Installing collected packages: cairocffi\n",
            "Successfully installed cairocffi-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install igraph pycairo cairocffi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "SmgeDqvqYQ71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmgeDqvqYQ71",
        "outputId": "70a10d9b-ca93-43c0-9d52-aeda36dfa208"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting GitPython\n",
            "  Using cached GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, GitPython\n",
            "Successfully installed GitPython-3.1.26 gitdb-4.0.9 smmap-5.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install GitPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "hZkBi3x541Sx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZkBi3x541Sx",
        "outputId": "94ca9d21-5bca-4736-bdda-e0dd9e9f6413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "sFM5JeIm49lW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFM5JeIm49lW",
        "outputId": "121314e1-34d7-4468-de47-73e80c54238d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.12\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.3.tar.gz (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 23.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 539 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.3-py3-none-any.whl size=581968 sha256=54afccd630981780108bf4636251933e29f03920eeaddb45294c52f8ba470577\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/2a/58/87ce0508964d4def1aafb92750c4f3ac77038efd1b9a89dcf5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.1 rdflib-6.1.1 torch-geometric-2.0.3 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "JjiASgG95DHK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjiASgG95DHK",
        "outputId": "b6927241-9dde-4e0d-f159-a9b8b10d04e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot) (3.0.7)\n"
          ]
        }
      ],
      "source": [
        "!apt install graphviz\n",
        "!pip install pydot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "gMc20S-n5VBr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMc20S-n5VBr",
        "outputId": "69618fea-3631-404c-c755-94e7ea9419f6"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch_sparse'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32md:\\Users\\zuev5\\TUM\\pytorch-GAT\\GAT_SG.ipynb Cell 14'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bwin/d%3A/Users/zuev5/TUM/pytorch-GAT/GAT_SG.ipynb#ch0000013vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m WordNet18\n\u001b[0;32m      <a href='vscode-notebook-cell://ssh-remote%2Bwin/d%3A/Users/zuev5/TUM/pytorch-GAT/GAT_SG.ipynb#ch0000013vscode-remote?line=1'>2</a>\u001b[0m wn18graph \u001b[39m=\u001b[39m WordNet18(root\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/wordnet18my\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell://ssh-remote%2Bwin/d%3A/Users/zuev5/TUM/pytorch-GAT/GAT_SG.ipynb#ch0000013vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n",
            "File \u001b[1;32md:\\Users\\zuev5\\TUM\\pytorch-GAT\\utils\\dataset.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/utils/dataset.py?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/utils/dataset.py?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/utils/dataset.py?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m InMemoryDataset, Data, download_url\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/utils/dataset.py?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m WordNet18 \u001b[39mas\u001b[39;00m WordNet18Original\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/utils/dataset.py?line=8'>9</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mWordNet18\u001b[39;00m(WordNet18Original):\n",
            "File \u001b[1;32md:\\Users\\zuev5\\TUM\\pytorch-GAT\\.venv\\lib\\site-packages\\torch_geometric\\__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m ModuleType\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimportlib\u001b[39;00m \u001b[39mimport\u001b[39;00m import_module\n\u001b[1;32m----> <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/__init__.py?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/__init__.py?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloader\u001b[39;00m\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/__init__.py?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m\n",
            "File \u001b[1;32md:\\Users\\zuev5\\TUM\\pytorch-GAT\\.venv\\lib\\site-packages\\torch_geometric\\data\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/data/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Data\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/data/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhetero_data\u001b[39;00m \u001b[39mimport\u001b[39;00m HeteroData\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/data/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtemporal\u001b[39;00m \u001b[39mimport\u001b[39;00m TemporalData\n",
            "File \u001b[1;32md:\\Users\\zuev5\\TUM\\pytorch-GAT\\.venv\\lib\\site-packages\\torch_geometric\\data\\data.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/data/data.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m (Optional, Dict, Any, Union, List, Iterable, Tuple,\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/data/data.py?line=1'>2</a>\u001b[0m                     NamedTuple, Callable)\n\u001b[1;32m----> <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/data/data.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m OptTensor, NodeType, EdgeType\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/data/data.py?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdeprecation\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecated\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/data/data.py?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcopy\u001b[39;00m\n",
            "File \u001b[1;32md:\\Users\\zuev5\\TUM\\pytorch-GAT\\.venv\\lib\\site-packages\\torch_geometric\\typing.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/typing.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Tuple, Optional, Union, List\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/typing.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor\n\u001b[1;32m----> <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/typing.py?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_sparse\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseTensor\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/typing.py?line=5'>6</a>\u001b[0m \u001b[39m# Types for accessing data ####################################################\u001b[39;00m\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/typing.py?line=6'>7</a>\u001b[0m \n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/typing.py?line=7'>8</a>\u001b[0m \u001b[39m# Node-types are denoted by a single string, e.g.: `data['paper']`:\u001b[39;00m\n\u001b[0;32m      <a href='file:///d%3A/Users/zuev5/TUM/pytorch-GAT/.venv/lib/site-packages/torch_geometric/typing.py?line=8'>9</a>\u001b[0m NodeType \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch_sparse'"
          ]
        }
      ],
      "source": [
        "from utils.dataset import WordNet18\n",
        "wn18graph = WordNet18(root='data/wordnet18my')\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "print(wordnet.synset_from_pos_and_offset('n', 3964744))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HJ5yivDteoZm",
      "metadata": {
        "id": "HJ5yivDteoZm"
      },
      "outputs": [],
      "source": [
        "from torchtext.vocab import GloVe\n",
        "glove = GloVe('6B', dim=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "treated-drama",
      "metadata": {
        "id": "treated-drama"
      },
      "source": [
        "# The Annotated GAT (PPI)\n",
        "\n",
        "This notebook is the 2nd part of the series, please check out **\"The Annotated GAT (Cora)\"** notebook for a more gentle introduction to GAT. ❤️\n",
        "\n",
        "The idea of this notebook is to explain how you can use GAT in an **inductive setting**. \n",
        "\n",
        "I'll be using the **PPI (protein-protein interaction) dataset** in this notebook.\n",
        "\n",
        "Here is a representation of the 3D structure of the protein [myoglobin](https://en.wikipedia.org/wiki/Protein) (not like you need to know anything about proteins in order to follow along this notebook it's just that they are beautiful and I love them 🍗❤️)!\n",
        "\n",
        "<img src=\"data/readme_pics/protein.png\" alt=\"protein schematic\" align=\"center\"/> <br/>\n",
        "\n",
        "In this notebook you'll get the answers to these questions:\n",
        "\n",
        "✅ How to load and visualize the PPI dataset? <br/>\n",
        "✅ How to train/use GAT on PPI (multi-label classification problem)? <br/>\n",
        "✅ How to visualize different GAT's properties? (mainly attention) <br/>\n",
        "\n",
        "Awesome, let's start!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "described-classroom",
      "metadata": {
        "id": "described-classroom"
      },
      "outputs": [],
      "source": [
        "# I always like to structure my imports into Python's native libs,\n",
        "# stuff I installed via conda/pip and local file imports (but we don't have those here)\n",
        "\n",
        "import json\n",
        "import os\n",
        "import enum\n",
        "\n",
        "# Visualization related imports\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from networkx.readwrite import json_graph\n",
        "import igraph as ig\n",
        "\n",
        "# Main computation libraries\n",
        "import numpy as np\n",
        "\n",
        "# Deep learning related imports\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "modified-electric",
      "metadata": {
        "id": "modified-electric"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Contains constants needed for data loading and visualization.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Supported datasets - only PPI in this notebook\n",
        "class DatasetType(enum.Enum):\n",
        "    PPI = 0\n",
        "\n",
        "    \n",
        "class GraphVisualizationTool(enum.Enum):\n",
        "    IGRAPH = 0\n",
        "\n",
        "\n",
        "# We'll be dumping and reading the data from this directory\n",
        "DATA_DIR_PATH = os.path.join(os.getcwd(), 'data')\n",
        "PPI_PATH = os.path.join(DATA_DIR_PATH, 'ppi')\n",
        "PPI_URL = 'https://data.dgl.ai/dataset/ppi.zip'  # preprocessed PPI data from Deep Graph Library\n",
        "\n",
        "#\n",
        "# PPI specific constants\n",
        "#\n",
        "\n",
        "PPI_NUM_INPUT_FEATURES = 50\n",
        "PPI_NUM_CLASSES = 121"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bacterial-failing",
      "metadata": {
        "id": "bacterial-failing"
      },
      "source": [
        "Note that some parts of this notebook overlap with \"The Annotated GAT (Cora)\" notebook, so you may see some redundancy. 🙏\n",
        "\n",
        "With that out of the way we've got the level 1 unlocked (Data 📜). 😍 Let's go!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "processed-mortality",
      "metadata": {
        "id": "processed-mortality"
      },
      "source": [
        "# Part 1: Understanding your data (become One with the data 📜❤️)\n",
        "\n",
        "I'll be using the PPI dataset as the running example in this notebook.\n",
        "\n",
        "Having said that, you may wonder, what's the difference between `transductive` and `inductive` setting? If you're not familiar with GNNs this may appear as a weird concept. But it's quite simple actually.\n",
        "\n",
        "**Transductive** - you have a single graph (like Cora) you split some **nodes** (and not graphs) into train/val/test training sets. While you're training you'll be using only the labels from your training nodes. BUT. During the forward prop, by the nature of how spatial GNNs work, you'll be aggregating the feature vectors from your neighbors and **some of them may belong to val or even test sets!** The main point is - you **ARE NOT** using their label information but you **ARE** using the structural information and their features.\n",
        "\n",
        "**Inductive** - you're probably much more familiar with this one if you come from the computer vision or NLP background. You have a set of training graphs, a separate set of val graphs and of course a separate set of test graphs.\n",
        "\n",
        "Having explained that let's jump into the code and let's load and visualize PPI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "variable-insulin",
      "metadata": {
        "id": "variable-insulin"
      },
      "outputs": [],
      "source": [
        "# First let's define this simple function for loading PPI's graph data\n",
        "\n",
        "def json_read(path):\n",
        "    with open(path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "outdoor-child",
      "metadata": {
        "id": "outdoor-child"
      },
      "source": [
        "Now let's see how we can load PPI!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HVH_7TGwTX4_",
      "metadata": {
        "id": "HVH_7TGwTX4_"
      },
      "outputs": [],
      "source": [
        "from torch.hub import download_url_to_file\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "metropolitan-programming",
      "metadata": {
        "id": "metropolitan-programming"
      },
      "outputs": [],
      "source": [
        "def load_graph_data(training_config, device):\n",
        "    dataset_name = training_config['dataset_name'].lower()\n",
        "    should_visualize = training_config['should_visualize']\n",
        "\n",
        "    if dataset_name == DatasetType.PPI.name.lower():  # Protein-Protein Interaction dataset\n",
        "\n",
        "        # Instead of checking PPI in, I'd rather download it on-the-fly the first time it's needed (lazy execution ^^)\n",
        "        if not os.path.exists(PPI_PATH):  # download the first time this is ran\n",
        "            os.makedirs(PPI_PATH)\n",
        "\n",
        "            # Step 1: Download the ppi.zip (contains the PPI dataset)\n",
        "            zip_tmp_path = os.path.join(PPI_PATH, 'ppi.zip')\n",
        "            download_url_to_file(PPI_URL, zip_tmp_path)\n",
        "\n",
        "            # Step 2: Unzip it\n",
        "            with zipfile.ZipFile(zip_tmp_path) as zf:\n",
        "                zf.extractall(path=PPI_PATH)\n",
        "            print(f'Unzipping to: {PPI_PATH} finished.')\n",
        "\n",
        "            # Step3: Remove the temporary resource file\n",
        "            os.remove(zip_tmp_path)\n",
        "            print(f'Removing tmp file {zip_tmp_path}.')\n",
        "\n",
        "        # Collect train/val/test graphs here\n",
        "        edge_index_list = []\n",
        "        node_features_list = []\n",
        "        node_labels_list = []\n",
        "\n",
        "        # Dynamically determine how many graphs we have per split (avoid using constants when possible)\n",
        "        num_graphs_per_split_cumulative = [0]\n",
        "\n",
        "        # Small optimization \"trick\" since we only need test in the playground.py\n",
        "        splits = ['test'] if training_config['ppi_load_test_only'] else ['train', 'valid', 'test']\n",
        "\n",
        "        for split in splits:\n",
        "            # PPI has 50 features per node, it's a combination of positional gene sets, motif gene sets,\n",
        "            # and immunological signatures - you can treat it as a black box (I personally have a rough understanding)\n",
        "            # shape = (NS, 50) - where NS is the number of (N)odes in the training/val/test (S)plit\n",
        "            # Note: node features are already preprocessed\n",
        "            node_features = np.load(os.path.join(PPI_PATH, f'{split}_feats.npy'))\n",
        "\n",
        "            # PPI has 121 labels and each node can have multiple labels associated (gene ontology stuff)\n",
        "            # SHAPE = (NS, 121)\n",
        "            node_labels = np.load(os.path.join(PPI_PATH, f'{split}_labels.npy'))\n",
        "\n",
        "            # Graph topology stored in a special nodes-links NetworkX format\n",
        "            nodes_links_dict = json_read(os.path.join(PPI_PATH, f'{split}_graph.json'))\n",
        "            # PPI contains undirected graphs with self edges - 20 train graphs, 2 validation graphs and 2 test graphs\n",
        "            # The reason I use a NetworkX's directed graph is because we need to explicitly model both directions\n",
        "            # because of the edge index and the way GAT implementation #3 works\n",
        "            collection_of_graphs = nx.DiGraph(json_graph.node_link_graph(nodes_links_dict))\n",
        "            # For each node in the above collection, ids specify to which graph the node belongs to\n",
        "            graph_ids = np.load(os.path.join(PPI_PATH, F'{split}_graph_id.npy'))\n",
        "            num_graphs_per_split_cumulative.append(num_graphs_per_split_cumulative[-1] + len(np.unique(graph_ids)))\n",
        "\n",
        "            # Split the collection of graphs into separate PPI graphs\n",
        "            for graph_id in range(np.min(graph_ids), np.max(graph_ids) + 1):\n",
        "                mask = graph_ids == graph_id  # find the nodes which belong to the current graph (identified via id)\n",
        "                graph_node_ids = np.asarray(mask).nonzero()[0]\n",
        "                graph = collection_of_graphs.subgraph(graph_node_ids)  # returns the induced subgraph over these nodes\n",
        "                print(f'Loading {split} graph {graph_id} to CPU. '\n",
        "                      f'It has {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.')\n",
        "\n",
        "                # shape = (2, E) - where E is the number of edges in the graph\n",
        "                # Note: leaving the tensors on CPU I'll load them to GPU in the training loop on-the-fly as VRAM\n",
        "                # is a scarcer resource than CPU's RAM and the whole PPI dataset can't fit during the training.\n",
        "                edge_index = torch.tensor(list(graph.edges), dtype=torch.long).transpose(0, 1).contiguous()\n",
        "                edge_index = edge_index - edge_index.min()  # bring the edges to [0, num_of_nodes] range\n",
        "                edge_index_list.append(edge_index)\n",
        "                # shape = (N, 50) - where N is the number of nodes in the graph\n",
        "                node_features_list.append(torch.tensor(node_features[mask], dtype=torch.float))\n",
        "                # shape = (N, 121), BCEWithLogitsLoss doesn't require long/int64 so saving some memory by using float32\n",
        "                node_labels_list.append(torch.tensor(node_labels[mask], dtype=torch.float))\n",
        "\n",
        "                if should_visualize:\n",
        "                    plot_in_out_degree_distributions(edge_index.numpy(), graph.number_of_nodes(), dataset_name)\n",
        "                    visualize_graph(edge_index.numpy(), node_labels[mask], dataset_name)\n",
        "\n",
        "        #\n",
        "        # Prepare graph data loaders\n",
        "        #\n",
        "\n",
        "        # Optimization, do a shortcut in case we only need the test data loader\n",
        "        if training_config['ppi_load_test_only']:\n",
        "            data_loader_test = GraphDataLoader(\n",
        "                node_features_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "                node_labels_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "                edge_index_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "                batch_size=training_config['batch_size'],\n",
        "                shuffle=False\n",
        "            )\n",
        "            return data_loader_test\n",
        "        else:\n",
        "\n",
        "            data_loader_train = GraphDataLoader(\n",
        "                node_features_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "                node_labels_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "                edge_index_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "                batch_size=training_config['batch_size'],\n",
        "                shuffle=True\n",
        "            )\n",
        "\n",
        "            data_loader_val = GraphDataLoader(\n",
        "                node_features_list[num_graphs_per_split_cumulative[1]:num_graphs_per_split_cumulative[2]],\n",
        "                node_labels_list[num_graphs_per_split_cumulative[1]:num_graphs_per_split_cumulative[2]],\n",
        "                edge_index_list[num_graphs_per_split_cumulative[1]:num_graphs_per_split_cumulative[2]],\n",
        "                batch_size=training_config['batch_size'],\n",
        "                shuffle=False  # no need to shuffle the validation and test graphs\n",
        "            )\n",
        "\n",
        "            data_loader_test = GraphDataLoader(\n",
        "                node_features_list[num_graphs_per_split_cumulative[2]:num_graphs_per_split_cumulative[3]],\n",
        "                node_labels_list[num_graphs_per_split_cumulative[2]:num_graphs_per_split_cumulative[3]],\n",
        "                edge_index_list[num_graphs_per_split_cumulative[2]:num_graphs_per_split_cumulative[3]],\n",
        "                batch_size=training_config['batch_size'],\n",
        "                shuffle=False\n",
        "            )\n",
        "\n",
        "            return data_loader_train, data_loader_val, data_loader_test\n",
        "    else:\n",
        "        raise Exception(f'{dataset_name} not yet supported.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jtvOmz_oeNws",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtvOmz_oeNws",
        "outputId": "3d9611b9-dcf7-40b0-841b-c8a3c55dfa7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Synset('white.n.01'), ['White', 'White_person', 'Caucasian'])\n",
            "(Synset('white.n.02'), ['white', 'whiteness'])\n",
            "(Synset('white.n.03'), ['White', 'Edward_White', 'Edward_D._White', 'Edward_Douglas_White_Jr.'])\n",
            "(Synset('white.n.04'), ['White', 'Patrick_White', 'Patrick_Victor_Martindale_White'])\n",
            "(Synset('white.n.05'), ['White', 'T._H._White', 'Theodore_Harold_White'])\n",
            "(Synset('white.n.06'), ['White', 'Stanford_White'])\n",
            "(Synset('white.n.07'), ['White', 'E._B._White', 'Elwyn_Brooks_White'])\n",
            "(Synset('white.n.08'), ['White', 'Andrew_D._White', 'Andrew_Dickson_White'])\n",
            "(Synset('white.n.09'), ['White', 'White_River'])\n",
            "(Synset('egg_white.n.01'), ['egg_white', 'white', 'albumen', 'ovalbumin'])\n",
            "(Synset('white.n.11'), ['white'])\n",
            "(Synset('flannel.n.03'), ['flannel', 'gabardine', 'tweed', 'white'])\n",
            "(Synset('whiten.v.01'), ['whiten', 'white'])\n",
            "(Synset('white.a.01'), ['white'])\n",
            "(Synset('white.a.02'), ['white'])\n",
            "(Synset('white.s.03'), ['white'])\n",
            "(Synset('white.s.04'), ['white', 'snowy'])\n",
            "(Synset('white.s.05'), ['white', 'lily-white'])\n",
            "(Synset('white.s.06'), ['white', 'white-hot'])\n",
            "(Synset('white.s.07'), ['white'])\n",
            "(Synset('blank.s.01'), ['blank', 'clean', 'white'])\n",
            "(Synset('white.s.09'), ['white'])\n",
            "(Synset('white.s.10'), ['white', 'whitened'])\n",
            "(Synset('ashen.s.01'), ['ashen', 'blanched', 'bloodless', 'livid', 'white'])\n",
            "(Synset('white.s.12'), ['white'])\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import wordnet\n",
        "for i in list(map(lambda x: (x, x.lemma_names(lang='eng')), wordnet.synsets('white'))):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vhY_93Evd3Ww",
      "metadata": {
        "id": "vhY_93Evd3Ww"
      },
      "outputs": [],
      "source": [
        "from utils.dataset import WordNet18\n",
        "dataset = WordNet18(root='data/wordnet18')\n",
        "data = dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bDlTwFBCfrAr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDlTwFBCfrAr",
        "outputId": "3cfc5819-95af-4266-e5ca-2b71b8a30de9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31550"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.entity2id['person.n.01']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1yvqF6XTgVBm",
      "metadata": {
        "id": "1yvqF6XTgVBm"
      },
      "outputs": [],
      "source": [
        "import pydot\n",
        "from IPython.display import SVG, display\n",
        "\n",
        "def view_pydot(pdot):\n",
        "    plt = SVG(pdot.create_svg())\n",
        "    display(plt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r9RpGxT_gZXd",
      "metadata": {
        "id": "r9RpGxT_gZXd"
      },
      "outputs": [],
      "source": [
        "def extend_wn_neighbors(g_node_synsets, g_node_features_words, g_node_labels_words, g_edge_index):\n",
        "    graph = pydot.Dot(\"my_graph\", graph_type=\"digraph\")\n",
        "\n",
        "\n",
        "def extend_wn_neighbors_node(synsets_to_classes, classes_to_synsets, node_synset):\n",
        "    next_idx = len(synsets_to_classes)\n",
        "    start = node_synset\n",
        "\n",
        "    node_synsets_extension = []\n",
        "    node_synset_to_node = {}\n",
        "    edge_index_extension = [\n",
        "        [],\n",
        "        []\n",
        "    ]\n",
        "\n",
        "    start_id = dataset.entity2id[start]\n",
        "    start_n = pydot.Node(start)\n",
        "    graph.add_node(start_n)\n",
        "\n",
        "    nodes = {start_id: start_n}\n",
        "\n",
        "    for (src, dst), edg in zip(data.edge_index.T, data.edge_type):\n",
        "        if src == start_id:\n",
        "            src_n = start_n\n",
        "            dest_id = dst.item()\n",
        "            dest = dataset.id2entity[dest_id]\n",
        "            dest_n = nodes.get(dest_id)\n",
        "            if dest_n is None:\n",
        "                dest_n = nodes[dest_id] = pydot.Node(dest)\n",
        "                graph.add_node(dest_n)\n",
        "            edge_id = edg.item()\n",
        "            edge = dataset.id2edge[edge_id]\n",
        "            edge_index_extension[0].append(src)\n",
        "            edge_index_extension[1].append(edge_id)\n",
        "            edge_index_extension[0].append(edge_id)\n",
        "            edge_index_extension[1].append(dst_id)\n",
        "            graph.add_edge(pydot.Edge(src_n, dest_n, label=edge))\n",
        "        elif dst == start_id:\n",
        "            dest_n = start_n\n",
        "            src_id = src.item()\n",
        "            src = dataset.id2entity[src_id]\n",
        "            src_n = nodes.get(src_id)\n",
        "            if src_n is None:\n",
        "                src_n = nodes[src_id] = pydot.Node(src)\n",
        "                graph.add_node(src_n)\n",
        "            edge_id = edg.item()\n",
        "            edge = dataset.id2edge[edge_id]\n",
        "            edge_index_extension[0].append(src)\n",
        "            edge_index_extension[1].append(dst)\n",
        "            graph.add_edge(pydot.Edge(src_n, dest_n, label=edge))\n",
        "    return graph\n",
        "#graph = extend_wn_neighbors(None)\n",
        "#view_pydot(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BVAWGQCfYIGv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVAWGQCfYIGv",
        "outputId": "3cd7f0a8-cdb7-4583-9f3c-c9bc2e17b864"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([7, 50]) torch.float32\n",
            "torch.Size([7]) torch.int64\n",
            "torch.Size([2, 6]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "# classes = [\n",
        "#     'none',\n",
        "#     'doctor',\n",
        "#     'farmer',\n",
        "#     'waiter',\n",
        "# ]\n",
        "# words_to_classes = {w: i for i, w in enumerate(classes)}\n",
        "\n",
        "edge_index_list = []\n",
        "node_features_list = []\n",
        "node_labels_list = []\n",
        "\n",
        "node_synsets_list = []\n",
        "synsets_to_classes = {}\n",
        "classes_to_synsets = []\n",
        "\n",
        "def get_synset_class(synsets_to_classes, classes_to_synsets, node_synset):\n",
        "    next_idx = len(synsets_to_classes)\n",
        "    if node_synset not in synsets_to_classes:\n",
        "        synsets_to_classes[node_synset] = next_idx\n",
        "        classes_to_synsets.append(node_synset)\n",
        "    return synsets_to_classes[node_synset]\n",
        "\n",
        "def class_of(s):\n",
        "    return get_synset_class(synsets_to_classes, classes_to_synsets, s)\n",
        "\n",
        "def make_graph(g_node_synsets, g_node_features_words, g_node_labels_words, g_edge_index):\n",
        "    g_node_features = torch.stack([\n",
        "        glove[word] for word in g_node_features_words\n",
        "    ])\n",
        "    #g_node_labels = torch.zeros(g_node_features.shape[0], len(classes))\n",
        "    #g_node_labels[range(g_node_features.shape[0]), [words_to_classes[w] for w in g_node_labels_words]] = 1\n",
        "    g_node_labels = torch.tensor([class_of(s) for s in g_node_synsets])\n",
        "    return g_edge_index, g_node_features, g_node_labels\n",
        "\n",
        "def append_graph(g_node_synsets, *args):\n",
        "    e, f, l = make_graph(g_node_synsets, *args)\n",
        "    edge_index_list.append(e)\n",
        "    node_features_list.append(f)\n",
        "    node_labels_list.append(l)\n",
        "\n",
        "    # collect synsets\n",
        "    # i = len(synsets_to_classes)  # next class idx\n",
        "    # for s in g_node_synsets:\n",
        "    #     if s not in synsets_to_classes:\n",
        "    #         synsets_to_classes[s] = i\n",
        "    #         classes_to_synsets.append(s)\n",
        "    #         i += 1\n",
        "\n",
        "# Graph 1        # 0              1            2                3            4            5          6\n",
        "g_node_synsets = ['person.n.01', 'hold.v.02', 'notebook.n.01', 'wear.v.01', 'coat.n.01', 'be.v.01', 'white.a.01']\n",
        "g_node_features_words = ['person', 'holds', 'notebook', 'wears', 'coat', 'is', 'white']\n",
        "g_node_labels_words = ['doctor', 'none', 'none', 'none', 'none', 'none', 'none']\n",
        "g_edge_index = torch.tensor([\n",
        "    [0, 1, 0, 3, 4, 5],\n",
        "    [1, 2, 3, 4, 5, 6],\n",
        "], dtype=torch.long)\n",
        "append_graph(g_node_synsets, g_node_features_words, g_node_labels_words, g_edge_index)\n",
        "\n",
        "# Graph 2        # 0              1            2\n",
        "g_node_synsets = ['person.n.01', 'hold.v.02', 'plant.n.02']\n",
        "g_node_features_words = ['person', 'holds', 'plant']\n",
        "g_node_labels_words = ['farmer', 'none', 'none']\n",
        "g_edge_index = torch.tensor([\n",
        "    [0, 1],\n",
        "    [1, 2],\n",
        "], dtype=torch.long)\n",
        "append_graph(g_node_synsets, g_node_features_words, g_node_labels_words, g_edge_index)\n",
        "\n",
        "# Graph 3        # 0              1            2             3               4\n",
        "g_node_synsets = ['person.n.01', 'hold.v.02', 'plate.n.04', 'contain.v.01', 'food.v.01']\n",
        "g_node_features_words = ['person', 'holds', 'plate', 'contains', 'food']\n",
        "g_node_labels_words = ['waiter', 'none', 'none', 'none', 'none']\n",
        "g_edge_index = torch.tensor([\n",
        "    [0, 1, 2, 3],\n",
        "    [1, 2, 3, 4],\n",
        "], dtype=torch.long)\n",
        "append_graph(g_node_synsets, g_node_features_words, g_node_labels_words, g_edge_index)\n",
        "\n",
        "# Graph 4=1      # 0              1            2            3          4\n",
        "g_node_synsets = ['person.n.01', 'wear.v.01', 'coat.n.01', 'be.v.01', 'white.a.01']\n",
        "g_node_features_words = ['person', 'wears', 'coat', 'is', 'white']\n",
        "g_node_labels_words = ['doctor', 'none', 'none', 'none', 'none']\n",
        "g_edge_index = torch.tensor([\n",
        "    [0, 1, 2, 3],\n",
        "    [1, 2, 3, 4],\n",
        "], dtype=torch.long)\n",
        "append_graph(g_node_synsets, g_node_features_words, g_node_labels_words, g_edge_index)\n",
        "\n",
        "print(node_features_list[0].shape, node_features_list[0].dtype)\n",
        "print(node_labels_list[0].shape, node_labels_list[0].dtype)\n",
        "print(edge_index_list[0].shape, edge_index_list[0].dtype)\n",
        "\n",
        "PPI_NUM_INPUT_FEATURES = 50\n",
        "PPI_NUM_CLASSES = len(synsets_to_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UdQLhS0WC968",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdQLhS0WC968",
        "outputId": "6ca6967d-b71c-4fd7-e501-a7721d36838b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'be.v.01': 5,\n",
              "  'coat.n.01': 4,\n",
              "  'contain.v.01': 9,\n",
              "  'food.v.01': 10,\n",
              "  'hold.v.02': 1,\n",
              "  'notebook.n.01': 2,\n",
              "  'person.n.01': 0,\n",
              "  'plant.n.02': 7,\n",
              "  'plate.n.04': 8,\n",
              "  'wear.v.01': 3,\n",
              "  'white.a.01': 6},\n",
              " ['person.n.01',\n",
              "  'hold.v.02',\n",
              "  'notebook.n.01',\n",
              "  'wear.v.01',\n",
              "  'coat.n.01',\n",
              "  'be.v.01',\n",
              "  'white.a.01',\n",
              "  'plant.n.02',\n",
              "  'plate.n.04',\n",
              "  'contain.v.01',\n",
              "  'food.v.01'])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "synsets_to_classes, classes_to_synsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93AV8ezFwvoW",
      "metadata": {
        "id": "93AV8ezFwvoW"
      },
      "outputs": [],
      "source": [
        "def hide_node(g_node_features, g_edge_index, g_node_labels, hide_node_idx=None):\n",
        "    # TODO: hide percentage of nodes\n",
        "    node_count = g_node_features.shape[0]\n",
        "    if hide_node_idx is None:\n",
        "        hide_node_idx = torch.randint(node_count, 1).item()\n",
        "    # replace features with random normal\n",
        "    g_node_features[hide_node_idx] = torch.normal(\n",
        "        mean=torch.full_like(g_node_features[hide_node_idx], 0.0),\n",
        "        std=torch.full_like(g_node_features[hide_node_idx], 1.0)\n",
        "    )\n",
        "    node_label = g_node_labels[hide_node_idx]\n",
        "    return g_node_features, g_edge_index, node_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CizvTqk420vN",
      "metadata": {
        "id": "CizvTqk420vN"
      },
      "outputs": [],
      "source": [
        "# edge_index_list = []\n",
        "# node_features_list = []\n",
        "# node_labels_list = []\n",
        "\n",
        "# node_synsets_list = []\n",
        "# synsets_to_classes = {}\n",
        "# classes_to_synsets = []\n",
        "hide_node_idx_list = [6, 0, 2, 2]\n",
        "hidden_node_labels_list = []\n",
        "\n",
        "for gi in range(len(node_labels_list)):\n",
        "    g_node_features = node_features_list[gi]\n",
        "    g_edge_index = edge_index_list[gi]\n",
        "    g_node_labels = node_labels_list[gi]\n",
        "    hide_node_idx = hide_node_idx_list[gi]\n",
        "\n",
        "    g_node_features, g_edge_index, node_label = hide_node(\n",
        "        g_node_features, g_edge_index, g_node_labels,\n",
        "        hide_node_idx=hide_node_idx\n",
        "    )\n",
        "\n",
        "    node_features_list[gi] = g_node_features\n",
        "    edge_index_list[gi] = g_edge_index\n",
        "    hidden_node_labels_list.append(node_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sh9RCSCqCmC8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh9RCSCqCmC8",
        "outputId": "88bb4612-a03a-4bca-d9d4-4f7e4ac90443"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor(6), tensor(0), tensor(8), tensor(4)]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden_node_labels_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P78P6I_uip25",
      "metadata": {
        "id": "P78P6I_uip25"
      },
      "outputs": [],
      "source": [
        "# torch.Size([3021, 50]) torch.float32\n",
        "# torch.Size([3021, 121]) torch.float32\n",
        "# torch.Size([2, 94359]) torch.int64\n",
        "#print(node_labels[0])\n",
        "#print()\n",
        "#print(g_node_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Dknyvq00W99I",
      "metadata": {
        "id": "Dknyvq00W99I"
      },
      "outputs": [],
      "source": [
        "# load my dataset\n",
        "def load_graph_data(training_config, device):\n",
        "    dataset_name = training_config['dataset_name'].lower()\n",
        "    should_visualize = training_config['should_visualize']\n",
        "\n",
        "    # Collect train/val/test graphs here\n",
        "    #edge_index_list = []\n",
        "    #node_features_list = []\n",
        "    #node_labels_list = []\n",
        "    num_graphs_per_split_cumulative = [0, 1, 2, 3]\n",
        "\n",
        "    #\n",
        "    # Prepare graph data loaders\n",
        "    #\n",
        "\n",
        "    # Optimization, do a shortcut in case we only need the test data loader\n",
        "    if training_config['ppi_load_test_only']:\n",
        "        data_loader_test = GraphDataLoader(\n",
        "            node_features_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "            node_labels_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "            edge_index_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "            hidden_node_labels_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "            batch_size=training_config['batch_size'],\n",
        "            shuffle=False\n",
        "        )\n",
        "        return data_loader_test\n",
        "    else:\n",
        "\n",
        "        num_graphs_per_split_cumulative = [0, -1, -1, -1]  # all\n",
        "        data_loader_train = GraphDataLoader(\n",
        "            node_features_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "            node_labels_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "            edge_index_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "            hidden_node_labels_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
        "            batch_size=training_config['batch_size'],\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        num_graphs_per_split_cumulative = [0, 0, -1, -1]  # all\n",
        "        data_loader_val = GraphDataLoader(\n",
        "            node_features_list[num_graphs_per_split_cumulative[1]:num_graphs_per_split_cumulative[2]],\n",
        "            node_labels_list[num_graphs_per_split_cumulative[1]:num_graphs_per_split_cumulative[2]],\n",
        "            edge_index_list[num_graphs_per_split_cumulative[1]:num_graphs_per_split_cumulative[2]],\n",
        "            hidden_node_labels_list[num_graphs_per_split_cumulative[1]:num_graphs_per_split_cumulative[2]],\n",
        "            batch_size=training_config['batch_size'],\n",
        "            shuffle=False  # no need to shuffle the validation and test graphs\n",
        "        )\n",
        "\n",
        "        num_graphs_per_split_cumulative = [0, 0, 0, -1]  # all\n",
        "        data_loader_test = GraphDataLoader(\n",
        "            node_features_list[num_graphs_per_split_cumulative[2]:num_graphs_per_split_cumulative[3]],\n",
        "            node_labels_list[num_graphs_per_split_cumulative[2]:num_graphs_per_split_cumulative[3]],\n",
        "            edge_index_list[num_graphs_per_split_cumulative[2]:num_graphs_per_split_cumulative[3]],\n",
        "            hidden_node_labels_list[num_graphs_per_split_cumulative[2]:num_graphs_per_split_cumulative[3]],\n",
        "            batch_size=training_config['batch_size'],\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        return data_loader_train, data_loader_val, data_loader_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tropical-watts",
      "metadata": {
        "id": "tropical-watts"
      },
      "source": [
        "Nice, there are is this `GraphDataLoader` object that we still haven't defined. We need it in order to load batches of PPI graphs into GAT.\n",
        "\n",
        "Here we go:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dental-frank",
      "metadata": {
        "id": "dental-frank"
      },
      "outputs": [],
      "source": [
        "class GraphDataLoader(DataLoader):\n",
        "    \"\"\"\n",
        "    When dealing with batches it's always a good idea to inherit from PyTorch's provided classes (Dataset/DataLoader).\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, node_features_list, node_labels_list, edge_index_list, hidden_node_idx_list, batch_size=1, shuffle=False):\n",
        "        graph_dataset = GraphDataset(node_features_list, node_labels_list, edge_index_list, hidden_node_idx_list)\n",
        "        # We need to specify a custom collate function, it doesn't work with the default one\n",
        "        super().__init__(graph_dataset, batch_size, shuffle, collate_fn=graph_collate_fn)\n",
        "\n",
        "\n",
        "class GraphDataset(Dataset):\n",
        "    \"\"\"\n",
        "    This one just fetches a single graph from the split when GraphDataLoader \"asks\" it\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, node_features_list, node_labels_list, edge_index_list, hidden_node_idx_list):\n",
        "        self.node_features_list = node_features_list\n",
        "        self.node_labels_list = node_labels_list\n",
        "        self.edge_index_list = edge_index_list\n",
        "        self.hidden_node_idx_list = hidden_node_idx_list\n",
        "\n",
        "    # 2 interface functions that need to be defined are len and getitem so that DataLoader can do it's magic\n",
        "    def __len__(self):\n",
        "        return len(self.edge_index_list)\n",
        "\n",
        "    def __getitem__(self, idx):  # we just fetch a single graph\n",
        "        return self.node_features_list[idx], self.node_labels_list[idx], self.edge_index_list[idx], self.hidden_node_idx_list[idx]\n",
        "\n",
        "\n",
        "def graph_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    The main idea here is to take multiple graphs from PPI as defined by the batch size\n",
        "    and merge them into a single graph with multiple connected components.\n",
        "\n",
        "    It's important to adjust the node ids in edge indices such that they form a consecutive range. Otherwise\n",
        "    the scatter functions in the implementation 3 will fail.\n",
        "\n",
        "    :param batch: contains a list of edge_index, node_features, node_labels tuples (as provided by the GraphDataset)\n",
        "    \"\"\"\n",
        "\n",
        "    edge_index_list = []\n",
        "    node_features_list = []\n",
        "    node_labels_list = []\n",
        "    hidden_node_idx_list = []\n",
        "    num_nodes_seen = 0\n",
        "\n",
        "    for features_labels_edge_index_tuple in batch:\n",
        "        # Just collect these into separate lists\n",
        "        node_features_list.append(features_labels_edge_index_tuple[0])\n",
        "        node_labels_list.append(features_labels_edge_index_tuple[1])\n",
        "\n",
        "        edge_index = features_labels_edge_index_tuple[2]  # all of the components are in the [0, N] range\n",
        "        hidden_node_idx_list.append(torch.tensor(features_labels_edge_index_tuple[3]))\n",
        "        edge_index_list.append(edge_index + num_nodes_seen)  # very important! translate the range of this component\n",
        "        num_nodes_seen += len(features_labels_edge_index_tuple[1])  # update the number of nodes we've seen so far\n",
        "\n",
        "    # Merge the PPI graphs into a single graph with multiple connected components\n",
        "    node_features = torch.cat(node_features_list, 0)\n",
        "    node_labels = torch.cat(node_labels_list, 0)\n",
        "    edge_index = torch.cat(edge_index_list, 1)\n",
        "    hidden_node_idx = torch.stack(hidden_node_idx_list)\n",
        "\n",
        "    return node_features, node_labels, edge_index, hidden_node_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V8ofeRl7-6ou",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8ofeRl7-6ou",
        "outputId": "ae644f59-f234-4c68-9d46-c9f607e8d335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 1])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.stack([torch.tensor(1), torch.tensor(1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "marine-mechanics",
      "metadata": {
        "id": "marine-mechanics"
      },
      "source": [
        "The idea is simple 💡 (as all things should be 😜). In order to pass a batch of graphs into GAT we do the following:\n",
        "\n",
        "1. During the preprocessing step, we map the edge index from the original range into the [0, N] range, where N is the number of nodes in a given graph. Example: the third graph in the training split may contain nodes [3500, ..., 5000] and thus originally its edge index would be in that very same range, e.g.: [3500, 4232], [3808, 4232], ...]. By subtracting the min element, 3500 in this case, we bring the edge index into [0, 1500] range.\n",
        "\n",
        "---\n",
        "\n",
        "2. In the `graph_collate_fn` function, edge indices are in the normalized range i.e. [0, N]. What we do is we shift them such that we end up with a single graph that actually consists out of multiple smaller PPI graphs which are not connected with each other i.e. they represent separate [connected components](https://www.geeksforgeeks.org/connected-components-in-an-undirected-graph/). \n",
        "\n",
        "---\n",
        "\n",
        "**Example:** let's say we have 3 graphs in a batch and all 3 edge indices are in the [0, 1000] range. What we'll do is the following: we'll leave the first graph without any modification, we'll shift second graph's range to [1000, 2000], because we had 1000 nodes in the graph that came before, and we'll shift the third graph's range into [2000, 3000], again because we had 2000 nodes that came before this graph. So the final edge index will have nodes in the [0, 3000] range and we treat that as a single graph with multiple connected components. 🤓\n",
        "\n",
        "Nice, finally let's try and load it. We should also analyze the shapes - that's always a good idea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unexpected-mercury",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unexpected-mercury",
        "outputId": "d815d981-b815-4f75-935a-a8b46552a74f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********************\n",
            "torch.Size([3, 50]) torch.float32\n",
            "torch.Size([3]) torch.int64\n",
            "torch.Size([2, 2]) torch.int64\n",
            "torch.Size([1]) torch.int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ],
      "source": [
        "# Let's just define dummy visualization functions for now - just to stop Python interpreter from complaining!\n",
        "# We'll define them in a moment, properly, I swear.\n",
        "\n",
        "def plot_in_out_degree_distributions():\n",
        "    pass\n",
        "\n",
        "def visualize_graph():\n",
        "    pass\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # checking whether you have a GPU\n",
        "\n",
        "config = {\n",
        "    'dataset_name': DatasetType.PPI.name,\n",
        "    'should_visualize': False,\n",
        "    'batch_size': 1,\n",
        "    'ppi_load_test_only': False  # small optimization for loading test graphs only, we won't use it here\n",
        "}\n",
        "\n",
        "data_loader_train, data_loader_val, data_loader_test = load_graph_data(config, device)\n",
        "# Let's fetch a single batch from the train graph data loader\n",
        "node_features, node_labels, edge_index, hidden_node_idx = next(iter(data_loader_train))\n",
        "\n",
        "print('*' * 20)\n",
        "print(node_features.shape, node_features.dtype)\n",
        "print(node_labels.shape, node_labels.dtype)\n",
        "print(edge_index.shape, edge_index.dtype)\n",
        "print(hidden_node_idx.shape, hidden_node_idx.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "expanded-friday",
      "metadata": {
        "id": "expanded-friday"
      },
      "source": [
        "Nice! Analyzing the shapes we see the following:\n",
        "1. This specific PPI train graph (batch size = 1) has 3021 nodes \n",
        "2. Each node has **50 features** (check out [data_loading.py](https://github.com/gordicaleksa/pytorch-GAT/blob/main/utils/data_loading.py) for much more detail)\n",
        "3. PPI has **121 classes** and each node can have multiple classes associated with it (multi-label classification dataset)\n",
        "4. This graph has 94359 edges (including the self edges)! (Compare this to 13k edges in Cora)\n",
        "5. PPI has **20 train** graphs, **2 validation** graphs and **2 test** graphs\n",
        "\n",
        "Additionally the edge index is of `int 64` type. Why? Well it's a constraint that PyTorch is imposing upon us. `index_select` functions require torch.long (i.e. 64 bit integer) and we use those in GAT implementation 3 - that's it.\n",
        "\n",
        "node_labels can be `float32` because `nn.BCEWithLogitsLoss` doesn't require long/int64 type (compare that to `nn.CrossEntropyLoss`, that we used in the Cora notebook, which does require int64s). So we can save up 2x memory! Not bad.\n",
        "\n",
        "---\n",
        "\n",
        "On the \"side note\", it's always a **good idea to test your code as you're progressing with your project.** \n",
        "\n",
        "Data loading is completely orthogonal to the rest of this notebook so we can test it, standalone, and make sure the shapes and datatypes make sense. I use this strategy while developing projects like this one (and in general).\n",
        "\n",
        "I start with data, I add the loading functionality, I add some visualizations and only then do I usually start developing the deep learning model itself.\n",
        "\n",
        "Visualizations are a huge bonus, so let's develop them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mediterranean-advancement",
      "metadata": {
        "id": "mediterranean-advancement"
      },
      "source": [
        "# Visualizing your data 🔮👓\n",
        "\n",
        "Let's start by understanding the degree distribution of nodes in PPI - i.e. how many input/output edges do nodes have, a certain measure of connectedness of the graph.\n",
        "\n",
        "Run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "welcome-construction",
      "metadata": {
        "id": "welcome-construction"
      },
      "outputs": [],
      "source": [
        "def plot_in_out_degree_distributions(edge_index, num_of_nodes, dataset_name):\n",
        "    \"\"\"\n",
        "        Note: It would be easy to do various kinds of powerful network analysis using igraph/networkx, etc.\n",
        "        I chose to explicitly calculate only the node degree statistics here, but you can go much further if needed and\n",
        "        calculate the graph diameter, number of triangles and many other concepts from the network analysis field.\n",
        "\n",
        "    \"\"\"\n",
        "    if isinstance(edge_index, torch.Tensor):\n",
        "        edge_index = edge_index.cpu().numpy()\n",
        "        \n",
        "    assert isinstance(edge_index, np.ndarray), f'Expected NumPy array got {type(edge_index)}.'\n",
        "\n",
        "    # Store each node's input and output degree (they're the same for undirected graphs such as Cora/PPI)\n",
        "    in_degrees = np.zeros(num_of_nodes, dtype=np.int)\n",
        "    out_degrees = np.zeros(num_of_nodes, dtype=np.int)\n",
        "\n",
        "    # Edge index shape = (2, E), the first row contains the source nodes, the second one target/sink nodes\n",
        "    # Note on terminology: source nodes point to target/sink nodes\n",
        "    num_of_edges = edge_index.shape[1]\n",
        "    for cnt in range(num_of_edges):\n",
        "        source_node_id = edge_index[0, cnt]\n",
        "        target_node_id = edge_index[1, cnt]\n",
        "\n",
        "        out_degrees[source_node_id] += 1  # source node points towards some other node -> increment it's out degree\n",
        "        in_degrees[target_node_id] += 1  # similarly here\n",
        "\n",
        "    hist = np.zeros(np.max(out_degrees) + 1)\n",
        "    for out_degree in out_degrees:\n",
        "        hist[out_degree] += 1\n",
        "\n",
        "    fig = plt.figure(figsize=(12,8), dpi=100)  # otherwise plots are really small in Jupyter Notebook\n",
        "    fig.subplots_adjust(hspace=0.6)\n",
        "\n",
        "    plt.subplot(311)\n",
        "    plt.plot(in_degrees, color='red')\n",
        "    plt.xlabel('node id'); plt.ylabel('in-degree count'); plt.title('Input degree for different node ids')\n",
        "\n",
        "    plt.subplot(312)\n",
        "    plt.plot(out_degrees, color='green')\n",
        "    plt.xlabel('node id'); plt.ylabel('out-degree count'); plt.title('Out degree for different node ids')\n",
        "\n",
        "    plt.subplot(313)\n",
        "    plt.plot(hist, color='blue')\n",
        "    plt.xlabel('node degree'); plt.ylabel('# nodes for a given out-degree'); plt.title(f'Node out-degree distribution for {dataset_name} dataset')\n",
        "    plt.xticks(np.arange(0, len(hist), 20.0))\n",
        "\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sublime-franklin",
      "metadata": {
        "id": "sublime-franklin"
      },
      "source": [
        "Brilliant, let's now visualize PPI's degree distributions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "optimum-clearance",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "optimum-clearance",
        "outputId": "c6acc8a9-f0aa-4196-afd1-9eac6e5db1e6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_of_nodes = len(node_labels)\n",
        "plot_in_out_degree_distributions(edge_index, num_of_nodes, config['dataset_name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ordinary-quantity",
      "metadata": {
        "id": "ordinary-quantity"
      },
      "source": [
        "You can immediately notice a couple of things:\n",
        "* The top 2 plots are the same, because we treat PPI as an undirected graph\n",
        "* Many more nodes have a large number of edges (compared to Cora), but still, most nodes have far less edges\n",
        "* The third plot nicely visualizes this in the form of a histogram - most nodes have only `1-20` edges (hence the peak on the leftmost side). But it's **more spread out compared to Cora.**\n",
        "\n",
        "Ok, we're starting to get some valuable insight into PPI, let's continue further and literally visualize/see PPI's graphs.\n",
        "\n",
        "The following cell will plot the training graph we fetched in one of the previous cells, run it. (*whispers: run it*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lyric-coordinate",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "lyric-coordinate",
        "outputId": "ece84f97-87f8-438f-8c10-a7a1564b4105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting results ... (it may take couple of seconds).\n"
          ]
        },
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"650pt\" height=\"650pt\" viewBox=\"0 0 650 650\" version=\"1.1\">\n<g id=\"surface2\">\n<rect x=\"0\" y=\"0\" width=\"650\" height=\"650\" style=\"fill:rgb(100%,100%,100%);fill-opacity:1;stroke:none;\"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 645 645 L 325 324.996094 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 325 324.996094 L 5 5 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 645.050781 645 C 645.050781 645.066406 644.949219 645.066406 644.949219 645 C 644.949219 644.933594 645.050781 644.933594 645.050781 645 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 325.101562 324.996094 C 325.101562 325.128906 324.902344 325.128906 324.902344 324.996094 C 324.902344 324.859375 325.101562 324.859375 325.101562 324.996094 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 5.050781 5 C 5.050781 5.066406 4.949219 5.066406 4.949219 5 C 4.949219 4.933594 5.050781 4.933594 5.050781 5 \"/>\n</g>\n</svg>\n",
            "text/plain": [
              "<igraph.drawing.Plot at 0x7f714a222490>"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "image/svg+xml": {
              "isolated": true
            }
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Check out this blog for available graph visualization tools:\n",
        "    https://towardsdatascience.com/large-graph-visualization-tools-and-approaches-2b8758a1cd59\n",
        "\n",
        "Basically depending on how big your graph is there may be better drawing tools than igraph.\n",
        "\n",
        "Note: I unfortunatelly had to flatten this function since igraph is having some problems with Jupyter Notebook,\n",
        "we'll only call it here so it's fine!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dataset_name = config['dataset_name']\n",
        "visualization_tool=GraphVisualizationTool.IGRAPH\n",
        "\n",
        "if isinstance(edge_index, torch.Tensor):\n",
        "    edge_index_np = edge_index.cpu().numpy()\n",
        "\n",
        "if isinstance(node_labels, torch.Tensor):\n",
        "    node_labels_np = node_labels.cpu().numpy()\n",
        "\n",
        "num_of_nodes = len(node_labels_np)\n",
        "edge_index_tuples = list(zip(edge_index_np[0, :], edge_index_np[1, :]))  # igraph requires this format\n",
        "\n",
        "# Construct the igraph graph\n",
        "ig_graph = ig.Graph()\n",
        "ig_graph.add_vertices(num_of_nodes)\n",
        "ig_graph.add_edges(edge_index_tuples)\n",
        "\n",
        "# Prepare the visualization settings dictionary\n",
        "visual_style = {}\n",
        "\n",
        "# Defines the size of the plot and margins\n",
        "visual_style[\"bbox\"] = (650, 650)\n",
        "visual_style[\"margin\"] = 5\n",
        "\n",
        "# I've chosen the edge thickness such that it's proportional to the number of shortest paths (geodesics)\n",
        "# that go through a certain edge in our graph (edge_betweenness function, a simple ad hoc heuristic)\n",
        "\n",
        "# line1: I use log otherwise some edges will be too thick and others not visible at all\n",
        "# edge_betweeness returns < 1 for certain edges that's why I use clip as log would be negative for those edges\n",
        "# line2: Normalize so that the thickest edge is 1 otherwise edges appear too thick on the chart\n",
        "# line3: The idea here is to make the strongest edge stay stronger than others, 6 just worked, don't dwell on it\n",
        "\n",
        "edge_weights_raw = np.clip(np.log(np.asarray(ig_graph.edge_betweenness())+1e-16), a_min=0, a_max=None)\n",
        "edge_weights_raw_normalized = edge_weights_raw / np.max(edge_weights_raw)\n",
        "edge_weights = [w**6 for w in edge_weights_raw_normalized]\n",
        "visual_style[\"edge_width\"] = edge_weights\n",
        "\n",
        "# A simple heuristic for vertex size.\n",
        "visual_style[\"vertex_size\"] = [deg / 10 for deg in ig_graph.degree()]\n",
        "\n",
        "# Set the layout - the way the graph is presented on a 2D chart. Graph drawing is a subfield for itself!\n",
        "# I used \"Kamada Kawai\" a force-directed method, this family of methods are based on physical system simulation.\n",
        "visual_style[\"layout\"] = ig_graph.layout_kamada_kawai()\n",
        "\n",
        "print('Plotting results ... (it may take couple of seconds).')\n",
        "ig.plot(ig_graph, **visual_style)\n",
        "\n",
        "# This website has got some awesome visualizations check it out:\n",
        "# http://networkrepository.com/graphvis.php?d=./data/gsm50/labeled/cora.edges"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "artistic-alpha",
      "metadata": {
        "id": "artistic-alpha"
      },
      "source": [
        "<img src=\"data/readme_pics/ppi_graph_jupyter.PNG\" alt=\"PPI visualized\" align=\"center\"/> <br/>\n",
        "\n",
        "**Note: I had to clear the original output of this cell when checking this notebook in, otherwise the file is huuge!** <br/>\n",
        "**I'm just showing you one arbitrary PPI training graph example here, yours may be different (there are 20 training graphs).**\n",
        "\n",
        "And I don't know about you, but I think this one is also beautiful! And it's **very different from Cora.** We can see much more edges.\n",
        "\n",
        "There are also multiple big nodes of similar size whereas in Cora a single node dominates the plot.\n",
        "\n",
        "Ok, we're done with visualizations and understanding our data. This is a huge milestone, so tap yourself on the back. 🏆🎂🎵\n",
        "\n",
        "We have the level 2 unlocked (the GAT model 🦄). 😍\n",
        "\n",
        "And now, let's understand the model! (just **skip the Part 2** and run the cells blindly **if you already went through the 1st part** of this GNN notebook series)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "emotional-regulation",
      "metadata": {
        "id": "emotional-regulation"
      },
      "source": [
        "# Part 2: Understanding GAT's inner workings 💻🦄\n",
        "\n",
        "First let's create a high level class where we'll build up `GAT` from `GatLayer` objects. \n",
        "\n",
        "It basically just stacks the layers into a nn.Sequential object and additionally since nn.Sequential expects a single input (and it has a single output) I just pack the data (features, edge index) into a tuple - *pure syntactic sugar*. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hourly-alert",
      "metadata": {
        "id": "hourly-alert"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    The most interesting and hardest implementation is implementation #3.\n",
        "    Imp1 and imp2 differ in subtle details but are basically the same thing.\n",
        "\n",
        "    So I'll focus on imp #3 in this notebook.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_of_layers, num_heads_per_layer, num_features_per_layer, add_skip_connection=True, bias=True,\n",
        "                 dropout=0.6, log_attention_weights=False):\n",
        "        super().__init__()\n",
        "        assert num_of_layers == len(num_heads_per_layer) == len(num_features_per_layer) - 1, f'Enter valid arch params.'\n",
        "\n",
        "        num_heads_per_layer = [1] + num_heads_per_layer  # trick - so that I can nicely create GAT layers below\n",
        "\n",
        "        gat_layers = []  # collect GAT layers\n",
        "        for i in range(num_of_layers):\n",
        "            layer = GATLayer(\n",
        "                num_in_features=num_features_per_layer[i] * num_heads_per_layer[i],  # consequence of concatenation\n",
        "                num_out_features=num_features_per_layer[i+1],\n",
        "                num_of_heads=num_heads_per_layer[i+1],\n",
        "                concat=True if i < num_of_layers - 1 else False,  # last GAT layer does mean avg, the others do concat\n",
        "                activation=nn.ELU() if i < num_of_layers - 1 else None,  # last layer just outputs raw scores\n",
        "                dropout_prob=dropout,\n",
        "                add_skip_connection=add_skip_connection,\n",
        "                bias=bias,\n",
        "                log_attention_weights=log_attention_weights\n",
        "            )\n",
        "            gat_layers.append(layer)\n",
        "\n",
        "        self.gat_net = nn.Sequential(\n",
        "            *gat_layers,\n",
        "        )\n",
        "\n",
        "    # data is just a (in_nodes_features, edge_index) tuple, I had to do it like this because of the nn.Sequential:\n",
        "    # https://discuss.pytorch.org/t/forward-takes-2-positional-arguments-but-3-were-given-for-nn-sqeuential-with-linear-layers/65698\n",
        "    def forward(self, data):\n",
        "        return self.gat_net(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "turkish-formula",
      "metadata": {
        "id": "turkish-formula"
      },
      "source": [
        "Now for the fun part let's define the layer. \n",
        "\n",
        "I really don't think that I can explain it any better, using words, than you taking your time to digest the code and the comments.\n",
        "\n",
        "Also make sure to check out [my video on GAT](https://www.youtube.com/watch?v=uFLeKkXWq2c) before you start losing time trying to figure it out \"from scratch\". It's always good to have some theoretical background at your hand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "outer-monitoring",
      "metadata": {
        "id": "outer-monitoring"
      },
      "outputs": [],
      "source": [
        "class GATLayer(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation #3 was inspired by PyTorch Geometric: https://github.com/rusty1s/pytorch_geometric\n",
        "\n",
        "    But, it's hopefully much more readable! (and of similar performance)\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    # We'll use these constants in many functions so just extracting them here as member fields\n",
        "    src_nodes_dim = 0  # position of source nodes in edge index\n",
        "    trg_nodes_dim = 1  # position of target nodes in edge index\n",
        "\n",
        "    # These may change in the inductive setting - leaving it like this for now (not future proof)\n",
        "    nodes_dim = 0      # node dimension (axis is maybe a more familiar term nodes_dim is the position of \"N\" in tensor)\n",
        "    head_dim = 1       # attention head dim\n",
        "\n",
        "    def __init__(self, num_in_features, num_out_features, num_of_heads, concat=True, activation=nn.ELU(),\n",
        "                 dropout_prob=0.6, add_skip_connection=True, bias=True, log_attention_weights=False):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_of_heads = num_of_heads\n",
        "        self.num_out_features = num_out_features\n",
        "        self.concat = concat  # whether we should concatenate or average the attention heads\n",
        "        self.add_skip_connection = add_skip_connection\n",
        "\n",
        "        #\n",
        "        # Trainable weights: linear projection matrix (denoted as \"W\" in the paper), attention target/source\n",
        "        # (denoted as \"a\" in the paper) and bias (not mentioned in the paper but present in the official GAT repo)\n",
        "        #\n",
        "\n",
        "        # You can treat this one matrix as num_of_heads independent W matrices\n",
        "        self.linear_proj = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=False)\n",
        "\n",
        "        # After we concatenate target node (node i) and source node (node j) we apply the \"additive\" scoring function\n",
        "        # which gives us un-normalized score \"e\". Here we split the \"a\" vector - but the semantics remain the same.\n",
        "        # Basically instead of doing [x, y] (concatenation, x/y are node feature vectors) and dot product with \"a\"\n",
        "        # we instead do a dot product between x and \"a_left\" and y and \"a_right\" and we sum them up\n",
        "        self.scoring_fn_target = nn.Parameter(torch.Tensor(1, num_of_heads, num_out_features))\n",
        "        self.scoring_fn_source = nn.Parameter(torch.Tensor(1, num_of_heads, num_out_features))\n",
        "\n",
        "        # Bias is definitely not crucial to GAT - feel free to experiment (I pinged the main author, Petar, on this one)\n",
        "        if bias and concat:\n",
        "            self.bias = nn.Parameter(torch.Tensor(num_of_heads * num_out_features))\n",
        "        elif bias and not concat:\n",
        "            self.bias = nn.Parameter(torch.Tensor(num_out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        if add_skip_connection:\n",
        "            self.skip_proj = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=False)\n",
        "        else:\n",
        "            self.register_parameter('skip_proj', None)\n",
        "\n",
        "        #\n",
        "        # End of trainable weights\n",
        "        #\n",
        "\n",
        "        self.leakyReLU = nn.LeakyReLU(0.2)  # using 0.2 as in the paper, no need to expose every setting\n",
        "        self.activation = activation\n",
        "        # Probably not the nicest design but I use the same module in 3 locations, before/after features projection\n",
        "        # and for attention coefficients. Functionality-wise it's the same as using independent modules.\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "        self.log_attention_weights = log_attention_weights  # whether we should log the attention weights\n",
        "        self.attention_weights = None  # for later visualization purposes, I cache the weights here\n",
        "\n",
        "        self.init_params()\n",
        "        \n",
        "    def forward(self, data):\n",
        "        #\n",
        "        # Step 1: Linear Projection + regularization\n",
        "        #\n",
        "\n",
        "        in_nodes_features, edge_index = data  # unpack data\n",
        "        num_of_nodes = in_nodes_features.shape[self.nodes_dim]\n",
        "        assert edge_index.shape[0] == 2, f'Expected edge index with shape=(2,E) got {edge_index.shape}'\n",
        "\n",
        "        # shape = (N, FIN) where N - number of nodes in the graph, FIN - number of input features per node\n",
        "        # We apply the dropout to all of the input node features (as mentioned in the paper)\n",
        "        in_nodes_features = self.dropout(in_nodes_features)\n",
        "\n",
        "        # shape = (N, FIN) * (FIN, NH*FOUT) -> (N, NH, FOUT) where NH - number of heads, FOUT - num of output features\n",
        "        # We project the input node features into NH independent output features (one for each attention head)\n",
        "        nodes_features_proj = self.linear_proj(in_nodes_features).view(-1, self.num_of_heads, self.num_out_features)\n",
        "\n",
        "        nodes_features_proj = self.dropout(nodes_features_proj)  # in the official GAT imp they did dropout here as well\n",
        "\n",
        "        #\n",
        "        # Step 2: Edge attention calculation\n",
        "        #\n",
        "\n",
        "        # Apply the scoring function (* represents element-wise (a.k.a. Hadamard) product)\n",
        "        # shape = (N, NH, FOUT) * (1, NH, FOUT) -> (N, NH, 1) -> (N, NH) because sum squeezes the last dimension\n",
        "        # Optimization note: torch.sum() is as performant as .sum() in my experiments\n",
        "        scores_source = (nodes_features_proj * self.scoring_fn_source).sum(dim=-1)\n",
        "        scores_target = (nodes_features_proj * self.scoring_fn_target).sum(dim=-1)\n",
        "\n",
        "        # We simply copy (lift) the scores for source/target nodes based on the edge index. Instead of preparing all\n",
        "        # the possible combinations of scores we just prepare those that will actually be used and those are defined\n",
        "        # by the edge index.\n",
        "        # scores shape = (E, NH), nodes_features_proj_lifted shape = (E, NH, FOUT), E - number of edges in the graph\n",
        "        scores_source_lifted, scores_target_lifted, nodes_features_proj_lifted = self.lift(scores_source, scores_target, nodes_features_proj, edge_index)\n",
        "        scores_per_edge = self.leakyReLU(scores_source_lifted + scores_target_lifted)\n",
        "\n",
        "        # shape = (E, NH, 1)\n",
        "        attentions_per_edge = self.neighborhood_aware_softmax(scores_per_edge, edge_index[self.trg_nodes_dim], num_of_nodes)\n",
        "        # Add stochasticity to neighborhood aggregation\n",
        "        attentions_per_edge = self.dropout(attentions_per_edge)\n",
        "\n",
        "        #\n",
        "        # Step 3: Neighborhood aggregation\n",
        "        #\n",
        "\n",
        "        # Element-wise (aka Hadamard) product. Operator * does the same thing as torch.mul\n",
        "        # shape = (E, NH, FOUT) * (E, NH, 1) -> (E, NH, FOUT), 1 gets broadcast into FOUT\n",
        "        nodes_features_proj_lifted_weighted = nodes_features_proj_lifted * attentions_per_edge\n",
        "\n",
        "        # This part sums up weighted and projected neighborhood feature vectors for every target node\n",
        "        # shape = (N, NH, FOUT)\n",
        "        out_nodes_features = self.aggregate_neighbors(nodes_features_proj_lifted_weighted, edge_index, in_nodes_features, num_of_nodes)\n",
        "\n",
        "        #\n",
        "        # Step 4: Residual/skip connections, concat and bias\n",
        "        #\n",
        "\n",
        "        out_nodes_features = self.skip_concat_bias(attentions_per_edge, in_nodes_features, out_nodes_features)\n",
        "        return (out_nodes_features, edge_index)\n",
        "\n",
        "    #\n",
        "    # Helper functions (without comments there is very little code so don't be scared!)\n",
        "    #\n",
        "\n",
        "    def neighborhood_aware_softmax(self, scores_per_edge, trg_index, num_of_nodes):\n",
        "        \"\"\"\n",
        "        As the fn name suggest it does softmax over the neighborhoods. Example: say we have 5 nodes in a graph.\n",
        "        Two of them 1, 2 are connected to node 3. If we want to calculate the representation for node 3 we should take\n",
        "        into account feature vectors of 1, 2 and 3 itself. Since we have scores for edges 1-3, 2-3 and 3-3\n",
        "        in scores_per_edge variable, this function will calculate attention scores like this: 1-3/(1-3+2-3+3-3)\n",
        "        (where 1-3 is overloaded notation it represents the edge 1-3 and its (exp) score) and similarly for 2-3 and 3-3\n",
        "         i.e. for this neighborhood we don't care about other edge scores that include nodes 4 and 5.\n",
        "\n",
        "        Note:\n",
        "        Subtracting the max value from logits doesn't change the end result but it improves the numerical stability\n",
        "        and it's a fairly common \"trick\" used in pretty much every deep learning framework.\n",
        "        Check out this link for more details:\n",
        "\n",
        "        https://stats.stackexchange.com/questions/338285/how-does-the-subtraction-of-the-logit-maximum-improve-learning\n",
        "\n",
        "        \"\"\"\n",
        "        # Calculate the numerator. Make logits <= 0 so that e^logit <= 1 (this will improve the numerical stability)\n",
        "        scores_per_edge = scores_per_edge - scores_per_edge.max()\n",
        "        exp_scores_per_edge = scores_per_edge.exp()  # softmax\n",
        "\n",
        "        # Calculate the denominator. shape = (E, NH)\n",
        "        neigborhood_aware_denominator = self.sum_edge_scores_neighborhood_aware(exp_scores_per_edge, trg_index, num_of_nodes)\n",
        "\n",
        "        # 1e-16 is theoretically not needed but is only there for numerical stability (avoid div by 0) - due to the\n",
        "        # possibility of the computer rounding a very small number all the way to 0.\n",
        "        attentions_per_edge = exp_scores_per_edge / (neigborhood_aware_denominator + 1e-16)\n",
        "\n",
        "        # shape = (E, NH) -> (E, NH, 1) so that we can do element-wise multiplication with projected node features\n",
        "        return attentions_per_edge.unsqueeze(-1)\n",
        "\n",
        "    def sum_edge_scores_neighborhood_aware(self, exp_scores_per_edge, trg_index, num_of_nodes):\n",
        "        # The shape must be the same as in exp_scores_per_edge (required by scatter_add_) i.e. from E -> (E, NH)\n",
        "        trg_index_broadcasted = self.explicit_broadcast(trg_index, exp_scores_per_edge)\n",
        "\n",
        "        # shape = (N, NH), where N is the number of nodes and NH the number of attention heads\n",
        "        size = list(exp_scores_per_edge.shape)  # convert to list otherwise assignment is not possible\n",
        "        size[self.nodes_dim] = num_of_nodes\n",
        "        neighborhood_sums = torch.zeros(size, dtype=exp_scores_per_edge.dtype, device=exp_scores_per_edge.device)\n",
        "\n",
        "        # position i will contain a sum of exp scores of all the nodes that point to the node i (as dictated by the\n",
        "        # target index)\n",
        "        neighborhood_sums.scatter_add_(self.nodes_dim, trg_index_broadcasted, exp_scores_per_edge)\n",
        "\n",
        "        # Expand again so that we can use it as a softmax denominator. e.g. node i's sum will be copied to\n",
        "        # all the locations where the source nodes pointed to i (as dictated by the target index)\n",
        "        # shape = (N, NH) -> (E, NH)\n",
        "        return neighborhood_sums.index_select(self.nodes_dim, trg_index)\n",
        "\n",
        "    def aggregate_neighbors(self, nodes_features_proj_lifted_weighted, edge_index, in_nodes_features, num_of_nodes):\n",
        "        size = list(nodes_features_proj_lifted_weighted.shape)  # convert to list otherwise assignment is not possible\n",
        "        size[self.nodes_dim] = num_of_nodes  # shape = (N, NH, FOUT)\n",
        "        out_nodes_features = torch.zeros(size, dtype=in_nodes_features.dtype, device=in_nodes_features.device)\n",
        "\n",
        "        # shape = (E) -> (E, NH, FOUT)\n",
        "        trg_index_broadcasted = self.explicit_broadcast(edge_index[self.trg_nodes_dim], nodes_features_proj_lifted_weighted)\n",
        "        # aggregation step - we accumulate projected, weighted node features for all the attention heads\n",
        "        # shape = (E, NH, FOUT) -> (N, NH, FOUT)\n",
        "        out_nodes_features.scatter_add_(self.nodes_dim, trg_index_broadcasted, nodes_features_proj_lifted_weighted)\n",
        "\n",
        "        return out_nodes_features\n",
        "\n",
        "    def lift(self, scores_source, scores_target, nodes_features_matrix_proj, edge_index):\n",
        "        \"\"\"\n",
        "        Lifts i.e. duplicates certain vectors depending on the edge index.\n",
        "        One of the tensor dims goes from N -> E (that's where the \"lift\" comes from).\n",
        "\n",
        "        \"\"\"\n",
        "        src_nodes_index = edge_index[self.src_nodes_dim]\n",
        "        trg_nodes_index = edge_index[self.trg_nodes_dim]\n",
        "\n",
        "        # Using index_select is faster than \"normal\" indexing (scores_source[src_nodes_index]) in PyTorch!\n",
        "        scores_source = scores_source.index_select(self.nodes_dim, src_nodes_index)\n",
        "        scores_target = scores_target.index_select(self.nodes_dim, trg_nodes_index)\n",
        "        nodes_features_matrix_proj_lifted = nodes_features_matrix_proj.index_select(self.nodes_dim, src_nodes_index)\n",
        "\n",
        "        return scores_source, scores_target, nodes_features_matrix_proj_lifted\n",
        "\n",
        "    def explicit_broadcast(self, this, other):\n",
        "        # Append singleton dimensions until this.dim() == other.dim()\n",
        "        for _ in range(this.dim(), other.dim()):\n",
        "            this = this.unsqueeze(-1)\n",
        "\n",
        "        # Explicitly expand so that shapes are the same\n",
        "        return this.expand_as(other)\n",
        "\n",
        "    def init_params(self):\n",
        "        \"\"\"\n",
        "        The reason we're using Glorot (aka Xavier uniform) initialization is because it's a default TF initialization:\n",
        "            https://stackoverflow.com/questions/37350131/what-is-the-default-variable-initializer-in-tensorflow\n",
        "\n",
        "        The original repo was developed in TensorFlow (TF) and they used the default initialization.\n",
        "        Feel free to experiment - there may be better initializations depending on your problem.\n",
        "\n",
        "        \"\"\"\n",
        "        nn.init.xavier_uniform_(self.linear_proj.weight)\n",
        "        nn.init.xavier_uniform_(self.scoring_fn_target)\n",
        "        nn.init.xavier_uniform_(self.scoring_fn_source)\n",
        "\n",
        "        if self.bias is not None:\n",
        "            torch.nn.init.zeros_(self.bias)\n",
        "\n",
        "    def skip_concat_bias(self, attention_coefficients, in_nodes_features, out_nodes_features):\n",
        "        if self.log_attention_weights:  # potentially log for later visualization in playground.py\n",
        "            self.attention_weights = attention_coefficients\n",
        "\n",
        "        if self.add_skip_connection:  # add skip or residual connection\n",
        "            if out_nodes_features.shape[-1] == in_nodes_features.shape[-1]:  # if FIN == FOUT\n",
        "                # unsqueeze does this: (N, FIN) -> (N, 1, FIN), out features are (N, NH, FOUT) so 1 gets broadcast to NH\n",
        "                # thus we're basically copying input vectors NH times and adding to processed vectors\n",
        "                out_nodes_features += in_nodes_features.unsqueeze(1)\n",
        "            else:\n",
        "                # FIN != FOUT so we need to project input feature vectors into dimension that can be added to output\n",
        "                # feature vectors. skip_proj adds lots of additional capacity which may cause overfitting.\n",
        "                out_nodes_features += self.skip_proj(in_nodes_features).view(-1, self.num_of_heads, self.num_out_features)\n",
        "\n",
        "        if self.concat:\n",
        "            # shape = (N, NH, FOUT) -> (N, NH*FOUT)\n",
        "            out_nodes_features = out_nodes_features.view(-1, self.num_of_heads * self.num_out_features)\n",
        "        else:\n",
        "            # shape = (N, NH, FOUT) -> (N, FOUT)\n",
        "            out_nodes_features = out_nodes_features.mean(dim=self.head_dim)\n",
        "\n",
        "        if self.bias is not None:\n",
        "            out_nodes_features += self.bias\n",
        "\n",
        "        return out_nodes_features if self.activation is None else self.activation(out_nodes_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "private-cemetery",
      "metadata": {
        "id": "private-cemetery"
      },
      "source": [
        "The main idea that leads to huge savings is that we calculate the scores only for the nodes that will actually be used and not for every imaginable combination (that would be valid only in a fully-connected graph).\n",
        "\n",
        "Once we compute the `\"left\"` scores and the `\"right\"` scores, we \"lift\" them up using the edge index. That way\n",
        "if the edge `1->2` is not present in the graph we won't have those score pairs in our data structure.\n",
        "\n",
        "After adding lifted \"left\" and \"right\" (or maybe a better naming would be source and target) scores we do smart `neighborhood-aware softmax` - so that the semantics of GAT is respected. After doing the `scatter add` (which you should take your time to understand and go through the docs) we can combine the projected feature vectors, and voilà, we got ourselves a fully-blown GAT layer.\n",
        "\n",
        "---\n",
        "\n",
        "Take your time and **be patient**! Especially if you're new to GNNs. \n",
        "\n",
        "I didn't learn all of this in 1 day, it takes time for the knowledge to sink in. You'll get there as well! ❤️ (if you're not already there 😜)\n",
        "\n",
        "Having said that, we've got the level 3 unlocked (model training 💪). 😍\n",
        "\n",
        "We have the data 📜 ready, we have the GAT model 🦄 ready, let's start training this beast! 💪"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "urban-involvement",
      "metadata": {
        "id": "urban-involvement"
      },
      "source": [
        "# Part 3: Training GAT 💪 (Multi-label classification on PPI!)\n",
        "\n",
        "Phew, well the hardest part is behind us. Let's know create a simple training loop where the goal is to learn to assign multiple labels to PPI nodes.\n",
        "\n",
        "But first let's define some relevant constants. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dense-criticism",
      "metadata": {
        "id": "dense-criticism"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "# 3 different model training/eval phases used in train.py\n",
        "class LoopPhase(enum.Enum):\n",
        "    TRAIN = 0,\n",
        "    VAL = 1,\n",
        "    TEST = 2\n",
        "\n",
        "    \n",
        "writer = SummaryWriter()  # (tensorboard) writer will output to ./runs/ directory by default\n",
        "\n",
        "\n",
        "# Global vars used for early stopping. After some number of epochs (as defined by the patience_period var) without any\n",
        "# improvement on the validation dataset (measured via micro-F1 metric), we'll break out from the training loop.\n",
        "BEST_VAL_MICRO_F1 = 0\n",
        "BEST_VAL_LOSS = 0\n",
        "PATIENCE_CNT = 0\n",
        "\n",
        "BINARIES_PATH = os.path.join(os.getcwd(), 'models', 'binaries')\n",
        "CHECKPOINTS_PATH = os.path.join(os.getcwd(), 'models', 'checkpoints')\n",
        "\n",
        "# Make sure these exist as the rest of the code assumes it\n",
        "os.makedirs(BINARIES_PATH, exist_ok=True)\n",
        "os.makedirs(CHECKPOINTS_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hungry-ebony",
      "metadata": {
        "id": "hungry-ebony"
      },
      "source": [
        "Also, let's define a couple of functions that will be useful while training the model.\n",
        "\n",
        "The training state contains a lot of useful `metadata` which we can later use. You can imagine that saving the test accuracy of your model is important, especially when you're training your models on a cloud - it makes the organization so much better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cardiac-federal",
      "metadata": {
        "id": "cardiac-federal"
      },
      "outputs": [],
      "source": [
        "import git\n",
        "import re  # regex\n",
        "\n",
        "\n",
        "def get_training_state(training_config, model):\n",
        "    training_state = {\n",
        "        \"commit_hash\": git.Repo(search_parent_directories=True).head.object.hexsha,\n",
        "\n",
        "        # Training details\n",
        "        \"dataset_name\": training_config['dataset_name'],\n",
        "        \"num_of_epochs\": training_config['num_of_epochs'],\n",
        "        \"test_perf\": training_config['test_perf'],\n",
        "\n",
        "        # Model structure\n",
        "        \"num_of_layers\": training_config['num_of_layers'],\n",
        "        \"num_heads_per_layer\": training_config['num_heads_per_layer'],\n",
        "        \"num_features_per_layer\": training_config['num_features_per_layer'],\n",
        "        \"add_skip_connection\": training_config['add_skip_connection'],\n",
        "        \"bias\": training_config['bias'],\n",
        "        \"dropout\": training_config['dropout'],\n",
        "\n",
        "        # Model state\n",
        "        \"state_dict\": model.state_dict()\n",
        "    }\n",
        "\n",
        "    return training_state\n",
        "\n",
        "\n",
        "def print_model_metadata(training_state):\n",
        "    header = f'\\n{\"*\"*5} Model training metadata: {\"*\"*5}'\n",
        "    print(header)\n",
        "\n",
        "    for key, value in training_state.items():\n",
        "        if key != 'state_dict':  # don't print state_dict it's a bunch of numbers...\n",
        "            print(f'{key}: {value}')\n",
        "    print(f'{\"*\" * len(header)}\\n')\n",
        "    \n",
        "\n",
        "# This one makes sure we don't overwrite the valuable model binaries (feel free to ignore - not crucial to GAT method)\n",
        "def get_available_binary_name(dataset_name='unknown'):\n",
        "    prefix = f'gat_{dataset_name}'\n",
        "\n",
        "    def valid_binary_name(binary_name):\n",
        "        # First time you see raw f-string? Don't worry the only trick is to double the brackets.\n",
        "        pattern = re.compile(rf'{prefix}_[0-9]{{6}}\\.pth')\n",
        "        return re.fullmatch(pattern, binary_name) is not None\n",
        "\n",
        "    # Just list the existing binaries so that we don't overwrite them but write to a new one\n",
        "    valid_binary_names = list(filter(valid_binary_name, os.listdir(BINARIES_PATH)))\n",
        "    if len(valid_binary_names) > 0:\n",
        "        last_binary_name = sorted(valid_binary_names)[-1]\n",
        "        new_suffix = int(last_binary_name.split('.')[0][-6:]) + 1  # increment by 1\n",
        "        return f'{prefix}_{str(new_suffix).zfill(6)}.pth'\n",
        "    else:\n",
        "        return f'{prefix}_000000.pth'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "binary-brother",
      "metadata": {
        "id": "binary-brother"
      },
      "source": [
        "Nice, now `argparse` is just a nice way to **organize** your program settings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MJt6lDgprSM1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJt6lDgprSM1",
        "outputId": "e8d527b9-6b6a-4999-d66c-b4f9253abe19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 11)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PPI_NUM_INPUT_FEATURES, PPI_NUM_CLASSES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "numerous-planet",
      "metadata": {
        "id": "numerous-planet"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "\n",
        "def get_training_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Training related\n",
        "    parser.add_argument(\"--num_of_epochs\", type=int, help=\"number of training epochs\", default=200)\n",
        "    parser.add_argument(\"--patience_period\", type=int, help=\"number of epochs with no improvement on val before terminating\", default=100)\n",
        "    parser.add_argument(\"--lr\", type=float, help=\"model learning rate\", default=5e-3)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, help=\"L2 regularization on model weights\", default=0)\n",
        "    parser.add_argument(\"--should_test\", type=bool, help='should test the model on the test dataset?', default=True)\n",
        "    parser.add_argument(\"--force_cpu\", type=bool, help='use CPU if your GPU is too small', default=False)\n",
        "\n",
        "    # Dataset related (note: we need the dataset name for metadata and related stuff, and not for picking the dataset)\n",
        "    parser.add_argument(\"--dataset_name\", choices=[el.name for el in DatasetType], help='dataset to use for training', default=DatasetType.PPI.name)\n",
        "    parser.add_argument(\"--batch_size\", type=int, help='number of graphs in a batch', default=2)\n",
        "    parser.add_argument(\"--should_visualize\", type=bool, help='should visualize the dataset?', default=False)\n",
        "\n",
        "    # Logging/debugging/checkpoint related (helps a lot with experimentation)\n",
        "    parser.add_argument(\"--enable_tensorboard\", type=bool, help=\"enable tensorboard logging\", default=False)\n",
        "    parser.add_argument(\"--console_log_freq\", type=int, help=\"log to output console (epoch) freq (None for no logging)\", default=10)\n",
        "    parser.add_argument(\"--checkpoint_freq\", type=int, help=\"checkpoint model saving (epoch) freq (None for no logging)\", default=5)\n",
        "    args = parser.parse_args('')\n",
        "\n",
        "    # I'm leaving the hyperparam values as reported in the paper, but I experimented a bit and the comments suggest\n",
        "    # how you can make GAT achieve an even higher micro-F1 or make it smaller\n",
        "    gat_config = {\n",
        "        # GNNs, contrary to CNNs, are often shallow (it ultimately depends on the graph properties)\n",
        "        \"num_of_layers\": 3,  # PPI has got 42% of nodes with all 0 features - that's why 3 layers are useful\n",
        "        \"num_heads_per_layer\": [4, 4, 6],  # other values may give even better results from the reported ones\n",
        "        \"num_features_per_layer\": [PPI_NUM_INPUT_FEATURES, 64, 64, PPI_NUM_CLASSES],  # 64 would also give ~0.975 uF1!\n",
        "        \"add_skip_connection\": True,  # skip connection is very important! (keep it otherwise micro-F1 is almost 0)\n",
        "        \"bias\": True,  # bias doesn't matter that much\n",
        "        \"dropout\": 0.0,  # dropout hurts the performance (best to keep it at 0)\n",
        "    }\n",
        "\n",
        "    # Wrapping training configuration into a dictionary\n",
        "    training_config = dict()\n",
        "    for arg in vars(args):\n",
        "        training_config[arg] = getattr(args, arg)\n",
        "    training_config['ppi_load_test_only'] = False  # load both train/val/test data loaders (don't change it)\n",
        "\n",
        "    # Add additional config information\n",
        "    training_config.update(gat_config)\n",
        "\n",
        "    return training_config"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "waiting-stanford",
      "metadata": {
        "id": "waiting-stanford"
      },
      "source": [
        "Now for the juicy part. 🍪🎅\n",
        "\n",
        "Here, we organize, high-level, everything we need for training GAT. Just combining the components we already learned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "apparent-precipitation",
      "metadata": {
        "id": "apparent-precipitation"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "\n",
        "def train_gat_ppi(config):\n",
        "    \"\"\"\n",
        "    Very similar to Cora's training script. The main differences are:\n",
        "    1. Using dataloaders since we're dealing with an inductive setting - multiple graphs per batch\n",
        "    2. Doing multi-class classification (BCEWithLogitsLoss) and reporting micro-F1 instead of accuracy\n",
        "    3. Model architecture and hyperparams are a bit different (as reported in the GAT paper)\n",
        "\n",
        "    \"\"\"\n",
        "    global BEST_VAL_MICRO_F1, BEST_VAL_LOSS\n",
        "\n",
        "    # Checking whether you have a strong GPU. Since PPI training requires almost 8 GBs of VRAM\n",
        "    # I've added the option to force the use of CPU even though you have a GPU on your system (but it's too weak).\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not config['force_cpu'] else \"cpu\")\n",
        "\n",
        "    # Step 1: prepare the data loaders\n",
        "    data_loader_train, data_loader_val, data_loader_test = load_graph_data(config, device)\n",
        "\n",
        "    # Step 2: prepare the model\n",
        "    gat = GAT(\n",
        "        num_of_layers=config['num_of_layers'],\n",
        "        num_heads_per_layer=config['num_heads_per_layer'],\n",
        "        num_features_per_layer=config['num_features_per_layer'],\n",
        "        add_skip_connection=config['add_skip_connection'],\n",
        "        bias=config['bias'],\n",
        "        dropout=config['dropout'],\n",
        "        log_attention_weights=False  # no need to store attentions, used only in playground.py for visualizations\n",
        "    ).to(device)\n",
        "\n",
        "    # Step 3: Prepare other training related utilities (loss & optimizer and decorator function)\n",
        "    #loss_fn = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "    #weight = torch.tensor([0.25] + ([1] * (PPI_NUM_CLASSES - 1)), dtype=torch.float32).to(device)\n",
        "    #print('weight =', weight)\n",
        "    #loss_fn = nn.CrossEntropyLoss(weight=weight, reduction='sum')\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(gat.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
        "\n",
        "    # The decorator function makes things cleaner since there is a lot of redundancy between the train and val loops\n",
        "    main_loop = get_main_loop(\n",
        "        config,\n",
        "        gat,\n",
        "        loss_fn,\n",
        "        optimizer,\n",
        "        config['patience_period'],\n",
        "        time.time())\n",
        "\n",
        "    BEST_VAL_MICRO_F1, BEST_VAL_LOSS, PATIENCE_CNT = [0, 0, 0]  # reset vars used for early stopping\n",
        "\n",
        "    # Step 4: Start the training procedure\n",
        "    for epoch in range(config['num_of_epochs']):\n",
        "        # Training loop\n",
        "        main_loop(phase=LoopPhase.TRAIN, data_loader=data_loader_train, epoch=epoch)\n",
        "\n",
        "        # Validation loop\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "                main_loop(phase=LoopPhase.VAL, data_loader=data_loader_val, epoch=epoch)\n",
        "            except Exception as e:  # \"patience has run out\" exception :O\n",
        "                print(str(e))\n",
        "                break  # break out from the training loop\n",
        "\n",
        "    # Step 5: Potentially test your model\n",
        "    # Don't overfit to the test dataset - only when you've fine-tuned your model on the validation dataset should you\n",
        "    # report your final loss and micro-F1 on the test dataset. Friends don't let friends overfit to the test data. <3\n",
        "    if config['should_test']:\n",
        "        micro_f1 = main_loop(phase=LoopPhase.TEST, data_loader=data_loader_test)\n",
        "        config['test_perf'] = micro_f1\n",
        "\n",
        "        print('*' * 50)\n",
        "        print(f'Test accuracy = {micro_f1}')\n",
        "    else:\n",
        "        config['test_perf'] = -1\n",
        "\n",
        "    # Save the latest GAT in the binaries directory\n",
        "    torch.save(\n",
        "        get_training_state(config, gat),\n",
        "        os.path.join(BINARIES_PATH, get_available_binary_name(config['dataset_name']))\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "western-grenada",
      "metadata": {
        "id": "western-grenada"
      },
      "source": [
        "🎉🎉🎉 \n",
        "\n",
        "Now for the core part of the training - the main loop, as I've dubbed it. \n",
        "\n",
        "I've organized it like this so that I don't have to copy/paste bunch of the same code for train/val/test loops.\n",
        "\n",
        "**Friends don't let friends copy/paste (unless it's from the Stack Overflow)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "comparative-heart",
      "metadata": {
        "id": "comparative-heart"
      },
      "outputs": [],
      "source": [
        "#from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "# Simple decorator function so that I don't have to pass arguments that don't change from epoch to epoch\n",
        "def get_main_loop(config, gat, sigmoid_cross_entropy_loss, optimizer, patience_period, time_start):\n",
        "\n",
        "    device = next(gat.parameters()).device  # fetch the device info from the model instead of passing it as a param\n",
        "\n",
        "    def main_loop(phase, data_loader, epoch=0):\n",
        "        global BEST_VAL_MICRO_F1, BEST_VAL_LOSS, PATIENCE_CNT, writer\n",
        "\n",
        "        # Certain modules behave differently depending on whether we're training the model or not.\n",
        "        # e.g. nn.Dropout - we only want to drop model weights during the training.\n",
        "        if phase == LoopPhase.TRAIN:\n",
        "            gat.train()\n",
        "        else:\n",
        "            gat.eval()\n",
        "\n",
        "        # Iterate over batches of graph data (2 graphs per batch was used in the original paper for the PPI dataset)\n",
        "        # We merge them into a single graph with 2 connected components, that's the main idea. After that\n",
        "        # the implementation #3 is agnostic to the fact that those are multiple and not a single graph!\n",
        "        for batch_idx, (node_features, gt_node_labels, edge_index, hidden_node_idx) in enumerate(data_loader):\n",
        "            # Push the batch onto GPU - note PPI is to big to load the whole dataset into a normal GPU\n",
        "            # it takes almost 8 GBs of VRAM to train it on a GPU\n",
        "            edge_index = edge_index.to(device)\n",
        "            node_features = node_features.to(device)\n",
        "            gt_node_labels = gt_node_labels.to(device)\n",
        "            hidden_node_idx = hidden_node_idx.to(device)\n",
        "\n",
        "            # I pack data into tuples because GAT uses nn.Sequential which expects this format\n",
        "            graph_data = (node_features, edge_index)\n",
        "\n",
        "            # Note: [0] just extracts the node_features part of the data (index 1 contains the edge_index)\n",
        "            # shape = (N, C) where N is the number of nodes in the batch and C is the number of classes (121 for PPI)\n",
        "            # GAT imp #3 is agnostic to the fact that we actually have multiple graphs\n",
        "            # (it sees a single graph with multiple connected components)\n",
        "            nodes_unnormalized_scores = gat(graph_data)[0]\n",
        "\n",
        "            # Example: because PPI has 121 labels let's make a simple toy example that will show how the loss works.\n",
        "            # Let's say we have 3 labels instead and a single node's unnormalized (raw GAT output) scores are [-3, 0, 3]\n",
        "            # What this loss will do is first it will apply a sigmoid and so we'll end up with: [0.048, 0.5, 0.95]\n",
        "            # next it will apply a binary cross entropy across all of these and find the average, and that's it!\n",
        "            # So if the true classes were [0, 0, 1] the loss would be (-log(1-0.048) + -log(1-0.5) + -log(0.95))/3.\n",
        "            # You can see that the logarithm takes 2 forms depending on whether the true label is 0 or 1,\n",
        "            # either -log(1-x) or -log(x) respectively. Easy-peasy. <3\n",
        "            #loss = sigmoid_cross_entropy_loss(nodes_unnormalized_scores, gt_node_labels)\n",
        "            \n",
        "            # Get label for the hidden node\n",
        "            #print(hidden_node_idx.shape, hidden_node_idx.dtype)\n",
        "            loss = sigmoid_cross_entropy_loss(\n",
        "                nodes_unnormalized_scores,\n",
        "                gt_node_labels\n",
        "            )\n",
        "\n",
        "            if phase == LoopPhase.TRAIN:\n",
        "                optimizer.zero_grad()  # clean the trainable weights gradients in the computational graph (.grad fields)\n",
        "                loss.backward()  # compute the gradients for every trainable weight in the computational graph\n",
        "                optimizer.step()  # apply the gradients to weights\n",
        "\n",
        "            # Calculate the main metric - micro F1, check out this link for what micro-F1 exactly is:\n",
        "            # https://www.kaggle.com/enforcer007/what-is-micro-averaged-f1-score\n",
        "\n",
        "            # Convert unnormalized scores into predictions. Explanation:\n",
        "            # If the unnormalized score is bigger than 0 that means that sigmoid would have a value higher than 0.5\n",
        "            # (by sigmoid's definition) and thus we have predicted 1 for that label otherwise we have predicted 0.\n",
        "            #pred = (nodes_unnormalized_scores > 0).float().cpu().numpy()\n",
        "            #print(nodes_unnormalized_scores, hidden_node_idx)\n",
        "            pred = nodes_unnormalized_scores[hidden_node_idx]\n",
        "            #print(gt_node_labels, hidden_node_idx)\n",
        "            gt = gt_node_labels[hidden_node_idx]\n",
        "            #micro_f1 = f1_score(gt, pred, average='micro')\n",
        "            print(gt.shape)\n",
        "            accuracy = torch.sum(torch.argmax(pred, dim=-1) == gt) / gt.shape[0]\n",
        "\n",
        "            #\n",
        "            # Logging\n",
        "            #\n",
        "\n",
        "            global_step = len(data_loader) * epoch + batch_idx\n",
        "            if phase == LoopPhase.TRAIN:\n",
        "                # Log metrics\n",
        "                if config['enable_tensorboard']:\n",
        "                    writer.add_scalar('training_loss', loss.item(), global_step)\n",
        "                    #writer.add_scalar('training_micro_f1', micro_f1, global_step)\n",
        "                    writer.add_scalar('training_accuracy', accuracy, global_step)\n",
        "\n",
        "                # Log to console\n",
        "                if config['console_log_freq'] is not None and epoch % config['console_log_freq'] == 0 and batch_idx == 0:\n",
        "                    print(f'GAT training: time elapsed= {(time.time() - time_start):.2f} [s] |'\n",
        "                          f' epoch={epoch + 1} | batch={batch_idx + 1} | train accuracy={accuracy}.')\n",
        "\n",
        "                # Save model checkpoint\n",
        "                if config['checkpoint_freq'] is not None and (epoch + 1) % config['checkpoint_freq'] == 0 and batch_idx == 0:\n",
        "                    ckpt_model_name = f'gat_{config[\"dataset_name\"]}_ckpt_epoch_{epoch + 1}.pth'\n",
        "                    config['test_perf'] = -1  # test perf not calculated yet, note: perf means main metric micro-F1 here\n",
        "                    torch.save(get_training_state(config, gat), os.path.join(CHECKPOINTS_PATH, ckpt_model_name))\n",
        "\n",
        "            elif phase == LoopPhase.VAL:\n",
        "                # Log metrics\n",
        "                if config['enable_tensorboard']:\n",
        "                    writer.add_scalar('val_loss', loss.item(), global_step)\n",
        "                    #writer.add_scalar('val_micro_f1', micro_f1, global_step)\n",
        "                    writer.add_scalar('val_accuracy', accuracy, global_step)\n",
        "\n",
        "                # Log to console\n",
        "                if config['console_log_freq'] is not None and epoch % config['console_log_freq'] == 0 and batch_idx == 0:\n",
        "                    print(f'GAT validation: time elapsed= {(time.time() - time_start):.2f} [s] |'\n",
        "                          f' epoch={epoch + 1} | batch={batch_idx + 1} | val accuracy={accuracy}')\n",
        "\n",
        "                # The \"patience\" logic - should we break out from the training loop? If either validation micro-F1\n",
        "                # keeps going up or the val loss keeps going down we won't stop\n",
        "                if accuracy > BEST_VAL_MICRO_F1 or loss.item() < BEST_VAL_LOSS:\n",
        "                    BEST_VAL_MICRO_F1 = max(accuracy, BEST_VAL_MICRO_F1)  # keep track of the best validation micro_f1 so far\n",
        "                    BEST_VAL_LOSS = min(loss.item(), BEST_VAL_LOSS)  # and the minimal loss\n",
        "                    PATIENCE_CNT = 0  # reset the counter every time we encounter new best micro_f1\n",
        "                else:\n",
        "                    PATIENCE_CNT += 1  # otherwise keep counting\n",
        "\n",
        "                if PATIENCE_CNT >= patience_period:\n",
        "                    raise Exception('Stopping the training, the universe has no more patience for this training.')\n",
        "\n",
        "            else:\n",
        "                return accuracy  # in the case of test phase we just report back the test accuracy\n",
        "\n",
        "    return main_loop  # return the decorated function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "numerical-stupid",
      "metadata": {
        "id": "numerical-stupid"
      },
      "source": [
        "That was all we needed! Let's train it! 💪💪💪\n",
        "\n",
        "Keep in mind that PPI training takes much more time than training on Cora.\n",
        "\n",
        "Additionally you'll need 8+ GBs GPU if you want to train it on your GPU. Alternatively you can set the `--force_cpu` flag in the `get_training_args` function to train it on your CPU or simply use the pre-checked-in model I provided. The following section, part 4, doesn't depend on this so you can skip it if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74UovIcqPefE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74UovIcqPefE",
        "outputId": "2feed4fc-bd87-4d92-9b7a-379bb95eca79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0]), 0, array([0]), 0)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(\n",
        "torch.tensor([0, 1, 7]).cpu()[torch.tensor([0])],\n",
        "torch.tensor([0, 1, 7]).cpu().numpy()[torch.tensor([0])],\n",
        "torch.tensor([0, 1, 7]).cpu()[torch.tensor([0])].numpy(),\n",
        "torch.tensor([0, 1, 7]).cpu()[torch.tensor([0])].item(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U5SpR22qAT7m",
      "metadata": {
        "id": "U5SpR22qAT7m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "local-details",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "local-details",
        "outputId": "536a4087-ff8f-4f23-c5fc-dd32da9d6a46"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-34f7cee92701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the graph attention network (GAT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_gat_ppi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_training_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-a4984b37b662>\u001b[0m in \u001b[0;36mtrain_gat_ppi\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dropout'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlog_attention_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m  \u001b[0;31m# no need to store attentions, used only in playground.py for visualizations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     ).to(device)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Step 3: Prepare other training related utilities (loss & optimizer and decorator function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    896\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ],
      "source": [
        "# Train the graph attention network (GAT)\n",
        "train_gat_ppi(get_training_args())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "roman-weather",
      "metadata": {
        "id": "roman-weather"
      },
      "source": [
        "Nice!!! 🎉🎉🎉 Level 4 unlocked (GAT visualizations 🔮). 😍\n",
        "\n",
        "We just achieved `0.978` micro-F1 on PPI's test graphs! The same numbers as reported in the original GAT paper!\n",
        "\n",
        "So we now have everything in place:\n",
        "1. PPI data loading and visualizations 📜 -> checked\n",
        "2. GAT model defined 🦄 -> checked\n",
        "3. Training loop setup and the trained model binaries 💪 -> checked\n",
        "\n",
        "Now let's play the GAT model under a microscope 🔬🔬🔬 and understand the weights we got - we can do that in many ways."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "constitutional-reach",
      "metadata": {
        "id": "constitutional-reach"
      },
      "source": [
        "# Part 4: Visualizing GAT on PPI 🔮\n",
        "\n",
        "I tried visualizing PPI's 2D embeddings using t-SNE without any label/color information but it's not that informative, so we'll only do **attention** and **entropy visualizations** in this notebook.\n",
        "\n",
        "Let's start by defining some functions we'll need. \n",
        "\n",
        "The following cell's code snippet will get called multiple times so let's just extract it inside a function - a nice modular design.\n",
        "\n",
        "*Note: the main reason is actually that igraph is having problems with Jupyter so I'm working around it, check out the [original code](https://github.com/gordicaleksa/pytorch-GAT/blob/main/playground.py#L147) if you're curious* 😂"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "satisfactory-yeast",
      "metadata": {
        "id": "satisfactory-yeast"
      },
      "outputs": [],
      "source": [
        "def gat_forward_pass(model_name, dataset_name):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # checking whether you have a GPU, I hope so!\n",
        "\n",
        "    config = {\n",
        "        'dataset_name': dataset_name,\n",
        "        'should_visualize': False,  # don't visualize the dataset\n",
        "        'batch_size': 2,  # we're using 2 graphs per batch as reported in the paper\n",
        "        'ppi_load_test_only': True  # optimization, we're loading only test graphs\n",
        "    }\n",
        "\n",
        "    # Step 1: Prepare the data\n",
        "    data_loader_test = load_graph_data(config, device)\n",
        "    node_features, node_labels, topology = next(iter(data_loader_test))\n",
        "    node_features = node_features.to(device)  # need to explicitly push them to GPU since PPI eats up a lot of VRAM\n",
        "    node_labels = node_labels.to(device)\n",
        "    topology = topology.to(device)\n",
        "\n",
        "    # Step 2: Prepare the model\n",
        "    model_path = os.path.join(BINARIES_PATH, model_name)\n",
        "    model_state = torch.load(model_path)\n",
        "\n",
        "    gat = GAT(\n",
        "        num_of_layers=model_state['num_of_layers'],\n",
        "        num_heads_per_layer=model_state['num_heads_per_layer'],\n",
        "        num_features_per_layer=model_state['num_features_per_layer'],\n",
        "        add_skip_connection=model_state['add_skip_connection'],\n",
        "        bias=model_state['bias'],\n",
        "        dropout=model_state['dropout'],\n",
        "        log_attention_weights=True\n",
        "    ).to(device)\n",
        "\n",
        "    print_model_metadata(model_state)\n",
        "    assert model_state['dataset_name'].lower() == dataset_name.lower(), \\\n",
        "        f\"The model was trained on {model_state['dataset_name']} but you're calling it on {dataset_name}.\"\n",
        "    gat.load_state_dict(model_state[\"state_dict\"], strict=True)\n",
        "    gat.eval()  # some layers like nn.Dropout behave differently in train vs eval mode so this part is important\n",
        "\n",
        "    # Step 3: Calculate the things we'll need for different visualization types (attention, scores, edge_index)\n",
        "\n",
        "    # This context manager is important (and you'll often see it), otherwise PyTorch will eat much more memory.\n",
        "    # It would be saving activations for backprop but we are not going to do any model training just the prediction.\n",
        "    with torch.no_grad():\n",
        "        # Step 3: Run predictions and collect the high dimensional data\n",
        "        all_nodes_unnormalized_scores, _ = gat((node_features, topology))  # shape = (N, num of classes)\n",
        "        all_nodes_unnormalized_scores = all_nodes_unnormalized_scores.cpu().numpy()\n",
        "\n",
        "    return all_nodes_unnormalized_scores, topology, node_labels, gat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mZunF2w0stBq",
      "metadata": {
        "id": "mZunF2w0stBq"
      },
      "outputs": [],
      "source": [
        "model_name = 'gat_PPI_000001.pth'\n",
        "dataset_name=DatasetType.PPI.name\n",
        "all_nodes_unnormalized_scores, edge_index, node_labels, gat = gat_forward_pass(model_name, dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G0pI3qJgs-9H",
      "metadata": {
        "id": "G0pI3qJgs-9H"
      },
      "outputs": [],
      "source": [
        "def printnp(a):\n",
        "    for row in a:\n",
        "        for col in row:\n",
        "            print('{: 4.2f}'.format(col), end=' ')\n",
        "        print('argmax =', np.argmax(row, axis=-1))\n",
        "\n",
        "#np.set_printoptions(suppress=True)\n",
        "for node_features, node_labels, edge_index in zip(node_features_list, node_labels_list, edge_index_list):\n",
        "    preds, _ = gat((node_features.cuda(), edge_index.cuda()))\n",
        "    preds = torch.softmax(preds, -1)\n",
        "    preds = preds.cpu().detach().numpy()\n",
        "    node_labels = node_labels.cpu().detach().numpy()\n",
        "    print('<' * 24)\n",
        "    printnp(preds)\n",
        "    print('-' * 24)\n",
        "    print(node_labels)\n",
        "    print('>' * 24)\n",
        "    #print(preds, node_labels, sep='\\n')\n",
        "#np.set_printoptions(suppress=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "extensive-drain",
      "metadata": {
        "id": "extensive-drain"
      },
      "source": [
        "Nice that one just produces the data that'll get consumed in the downstream visualizations that you'll see defined in the following cells."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "impressed-tamil",
      "metadata": {
        "id": "impressed-tamil"
      },
      "source": [
        "# Visualizing neighborhood attention 📣\n",
        "\n",
        "So, you now hopefully understand how GAT roughly works, and so you know that during the aggregation stage every single node assigns an **attention coefficient** to every single one of its neighbors (including itself since we added self edges).\n",
        "\n",
        "Any ideas on what we could visualize? Well let's pick some nodes and see which attention patterns they've learned!\n",
        "\n",
        "The first idea that may pop to your mind is to draw edges **thicker** if the **attention is larger** and vice versa (*well that's also the last idea that pops to my mind*).\n",
        "\n",
        "Let's do it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "combined-ceiling",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "combined-ceiling",
        "outputId": "92c528d1-d83a-45c1-9e28-a1ced60a7e9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading test graph 23 to CPU. It has 3224 nodes and 103872 edges.\n",
            "Loading test graph 24 to CPU. It has 2300 nodes and 63628 edges.\n",
            "\n",
            "***** Model training metadata: *****\n",
            "commit_hash: ad028f5d4bdb533020a73c6ffcacfb2fd9767539\n",
            "dataset_name: PPI\n",
            "num_of_epochs: 200\n",
            "test_perf: 0.9779919847816116\n",
            "num_of_layers: 3\n",
            "num_heads_per_layer: [4, 4, 6]\n",
            "num_features_per_layer: [50, 256, 256, 121]\n",
            "add_skip_connection: True\n",
            "bias: True\n",
            "dropout: 0.0\n",
            "layer_type: IMP3\n",
            "*************************************\n",
            "\n",
            "tensor([False, False, False,  ..., False, False, False], device='cuda:0')\n",
            "Max attention weight = 0.7059098482131958 and min = 0.0023552586790174246\n"
          ]
        },
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600pt\" height=\"600pt\" viewBox=\"0 0 600 600\" version=\"1.1\">\n<g id=\"surface8\">\n<rect x=\"0\" y=\"0\" width=\"600\" height=\"600\" style=\"fill:rgb(100%,100%,100%);fill-opacity:1;stroke:none;\"/>\n<path style=\"fill:none;stroke-width:0.00769083;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 323.871094 289.585938 C 323.871094 297.871094 317.15625 304.585938 308.871094 304.585938 C 300.589844 304.585938 293.871094 297.871094 293.871094 289.585938 C 293.871094 281.300781 300.589844 274.585938 308.871094 274.585938 C 317.15625 274.585938 323.871094 281.300781 323.871094 289.585938 \"/>\n<path style=\"fill:none;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 580 300.191406 \"/>\n<path style=\"fill:none;stroke-width:0.00616214;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 564.652344 391.636719 \"/>\n<path style=\"fill:none;stroke-width:0.0187682;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 520.273438 473.117188 \"/>\n<path style=\"fill:none;stroke-width:0.00333649;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 451.710938 535.753906 \"/>\n<path style=\"fill:none;stroke-width:0.00675488;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 366.421875 572.726562 \"/>\n<path style=\"fill:none;stroke-width:0.0154947;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 273.710938 580 \"/>\n<path style=\"fill:none;stroke-width:0.00675488;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 183.675781 556.785156 \"/>\n<path style=\"fill:none;stroke-width:0.00361774;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 106.125 505.613281 \"/>\n<path style=\"fill:none;stroke-width:0.00793732;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 49.507812 432.054688 \"/>\n<path style=\"fill:none;stroke-width:0.00784118;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 20 344.132812 \"/>\n<path style=\"fill:none;stroke-width:0.00784118;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 20.8125 251.417969 \"/>\n<path style=\"fill:none;stroke-width:0.00624381;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 51.855469 164.019531 \"/>\n<path style=\"fill:none;stroke-width:0.271425;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 109.75 91.460938 \"/>\n<path style=\"fill:none;stroke-width:0.00784118;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 188.183594 41.644531 \"/>\n<path style=\"fill:none;stroke-width:0.00748776;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 278.613281 20 \"/>\n<path style=\"fill:none;stroke-width:0.00784118;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 371.183594 28.886719 \"/>\n<path style=\"fill:none;stroke-width:0.00675488;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 455.808594 67.335938 \"/>\n<path style=\"fill:none;stroke-width:0.00784118;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 523.269531 131.15625 \"/>\n<path style=\"fill:none;stroke-width:0.00897365;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(26.666667%,26.666667%,26.666667%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 298.265625 300.191406 L 566.210938 213.398438 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 308.265625 300.191406 C 308.265625 305.714844 303.789062 310.191406 298.265625 310.191406 C 292.742188 310.191406 288.265625 305.714844 288.265625 300.191406 C 288.265625 294.667969 292.742188 290.191406 298.265625 290.191406 C 303.789062 290.191406 308.265625 294.667969 308.265625 300.191406 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 590 300.191406 C 590 305.714844 585.523438 310.191406 580 310.191406 C 574.476562 310.191406 570 305.714844 570 300.191406 C 570 294.667969 574.476562 290.191406 580 290.191406 C 585.523438 290.191406 590 294.667969 590 300.191406 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 574.652344 391.636719 C 574.652344 397.160156 570.171875 401.636719 564.652344 401.636719 C 559.128906 401.636719 554.652344 397.160156 554.652344 391.636719 C 554.652344 386.113281 559.128906 381.636719 564.652344 381.636719 C 570.171875 381.636719 574.652344 386.113281 574.652344 391.636719 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 530.273438 473.117188 C 530.273438 478.640625 525.796875 483.117188 520.273438 483.117188 C 514.753906 483.117188 510.273438 478.640625 510.273438 473.117188 C 510.273438 467.59375 514.753906 463.117188 520.273438 463.117188 C 525.796875 463.117188 530.273438 467.59375 530.273438 473.117188 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 461.710938 535.753906 C 461.710938 541.277344 457.230469 545.753906 451.710938 545.753906 C 446.1875 545.753906 441.710938 541.277344 441.710938 535.753906 C 441.710938 530.230469 446.1875 525.753906 451.710938 525.753906 C 457.230469 525.753906 461.710938 530.230469 461.710938 535.753906 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 376.421875 572.726562 C 376.421875 578.25 371.945312 582.726562 366.421875 582.726562 C 360.902344 582.726562 356.421875 578.25 356.421875 572.726562 C 356.421875 567.203125 360.902344 562.726562 366.421875 562.726562 C 371.945312 562.726562 376.421875 567.203125 376.421875 572.726562 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 283.710938 580 C 283.710938 585.523438 279.234375 590 273.710938 590 C 268.1875 590 263.710938 585.523438 263.710938 580 C 263.710938 574.476562 268.1875 570 273.710938 570 C 279.234375 570 283.710938 574.476562 283.710938 580 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 193.675781 556.785156 C 193.675781 562.308594 189.195312 566.785156 183.675781 566.785156 C 178.152344 566.785156 173.675781 562.308594 173.675781 556.785156 C 173.675781 551.261719 178.152344 546.785156 183.675781 546.785156 C 189.195312 546.785156 193.675781 551.261719 193.675781 556.785156 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 116.125 505.613281 C 116.125 511.136719 111.644531 515.613281 106.125 515.613281 C 100.601562 515.613281 96.125 511.136719 96.125 505.613281 C 96.125 500.089844 100.601562 495.613281 106.125 495.613281 C 111.644531 495.613281 116.125 500.089844 116.125 505.613281 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 59.507812 432.054688 C 59.507812 437.578125 55.03125 442.054688 49.507812 442.054688 C 43.984375 442.054688 39.507812 437.578125 39.507812 432.054688 C 39.507812 426.53125 43.984375 422.054688 49.507812 422.054688 C 55.03125 422.054688 59.507812 426.53125 59.507812 432.054688 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 30 344.132812 C 30 349.652344 25.523438 354.132812 20 354.132812 C 14.476562 354.132812 10 349.652344 10 344.132812 C 10 338.609375 14.476562 334.132812 20 334.132812 C 25.523438 334.132812 30 338.609375 30 344.132812 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 30.8125 251.417969 C 30.8125 256.941406 26.335938 261.417969 20.8125 261.417969 C 15.289062 261.417969 10.8125 256.941406 10.8125 251.417969 C 10.8125 245.894531 15.289062 241.417969 20.8125 241.417969 C 26.335938 241.417969 30.8125 245.894531 30.8125 251.417969 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 61.855469 164.019531 C 61.855469 169.542969 57.378906 174.019531 51.855469 174.019531 C 46.332031 174.019531 41.855469 169.542969 41.855469 164.019531 C 41.855469 158.496094 46.332031 154.019531 51.855469 154.019531 C 57.378906 154.019531 61.855469 158.496094 61.855469 164.019531 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 119.75 91.460938 C 119.75 96.984375 115.273438 101.460938 109.75 101.460938 C 104.226562 101.460938 99.75 96.984375 99.75 91.460938 C 99.75 85.9375 104.226562 81.460938 109.75 81.460938 C 115.273438 81.460938 119.75 85.9375 119.75 91.460938 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 198.183594 41.644531 C 198.183594 47.167969 193.707031 51.644531 188.183594 51.644531 C 182.660156 51.644531 178.183594 47.167969 178.183594 41.644531 C 178.183594 36.121094 182.660156 31.644531 188.183594 31.644531 C 193.707031 31.644531 198.183594 36.121094 198.183594 41.644531 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 288.613281 20 C 288.613281 25.523438 284.136719 30 278.613281 30 C 273.089844 30 268.613281 25.523438 268.613281 20 C 268.613281 14.476562 273.089844 10 278.613281 10 C 284.136719 10 288.613281 14.476562 288.613281 20 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 381.183594 28.886719 C 381.183594 34.410156 376.707031 38.886719 371.183594 38.886719 C 365.660156 38.886719 361.183594 34.410156 361.183594 28.886719 C 361.183594 23.363281 365.660156 18.886719 371.183594 18.886719 C 376.707031 18.886719 381.183594 23.363281 381.183594 28.886719 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 465.808594 67.335938 C 465.808594 72.859375 461.332031 77.335938 455.808594 77.335938 C 450.285156 77.335938 445.808594 72.859375 445.808594 67.335938 C 445.808594 61.8125 450.285156 57.335938 455.808594 57.335938 C 461.332031 57.335938 465.808594 61.8125 465.808594 67.335938 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 533.269531 131.15625 C 533.269531 136.679688 528.792969 141.15625 523.269531 141.15625 C 517.746094 141.15625 513.269531 136.679688 513.269531 131.15625 C 513.269531 125.632812 517.746094 121.15625 523.269531 121.15625 C 528.792969 121.15625 533.269531 125.632812 533.269531 131.15625 \"/>\n<path style=\"fill-rule:nonzero;fill:rgb(100%,0%,0%);fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 576.210938 213.398438 C 576.210938 218.917969 571.734375 223.398438 566.210938 223.398438 C 560.6875 223.398438 556.210938 218.917969 556.210938 213.398438 C 556.210938 207.875 560.6875 203.398438 566.210938 203.398438 C 571.734375 203.398438 576.210938 207.875 576.210938 213.398438 \"/>\n</g>\n</svg>\n",
            "text/plain": [
              "<igraph.drawing.Plot at 0x7f6920add250>"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "image/svg+xml": {
              "isolated": true
            }
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Again, unfortunately, igraph is having some problems running in Jupyter so I have to flatten out the content here\n",
        "# including the for loops - no for loops with igraph in Jupyter folks.\n",
        "\n",
        "model_name=r'gat_PPI_000000.pth'  # This model is checked-in, feel free to use the one you trained\n",
        "dataset_name=DatasetType.PPI.name\n",
        "\n",
        "# Fetch the data we'll need to create visualizations\n",
        "all_nodes_unnormalized_scores, edge_index, node_labels, gat = gat_forward_pass(model_name, dataset_name)\n",
        "\n",
        "# The number of nodes for which we want to visualize their attention over neighboring nodes\n",
        "# (2x this actually as we add nodes with highest degree + random nodes)\n",
        "num_nodes_of_interest = 4  # 4 is an arbitrary number you can play with these numbers\n",
        "head_to_visualize = 0  # plot attention from this multi-head attention's head\n",
        "gat_layer_id = 0  # plot attention from this GAT layer\n",
        "\n",
        "assert gat_layer_id == 0, f'Attention visualization for {dataset_name} is only available for the first layer.'\n",
        "\n",
        "# Build up the complete graph\n",
        "# node_features shape = (N, FIN), where N is the number of nodes and FIN number of input features\n",
        "total_num_of_nodes = len(all_nodes_unnormalized_scores)\n",
        "complete_graph = ig.Graph()\n",
        "complete_graph.add_vertices(total_num_of_nodes)  # igraph creates nodes with ids [0, total_num_of_nodes - 1]\n",
        "edge_index_tuples = list(zip(edge_index[0, :], edge_index[1, :]))  # igraph requires this format\n",
        "complete_graph.add_edges(edge_index_tuples)\n",
        "\n",
        "target_node_ids = edge_index[1]\n",
        "source_nodes = edge_index[0]\n",
        "\n",
        "#\n",
        "# Pick the node id you want to visualize the attention for!\n",
        "#\n",
        "\n",
        "# since for loops won't work with igraph just set some number here\n",
        "target_node_id = 0  # random node\n",
        "\n",
        "# Step 1: Find the neighboring nodes to the target node\n",
        "# Note: self edges are included so the target node is it's own neighbor (Alexandro yo soy tu madre)\n",
        "src_nodes_indices = torch.eq(target_node_ids, target_node_id)\n",
        "source_node_ids = source_nodes[src_nodes_indices].cpu().numpy()\n",
        "size_of_neighborhood = len(source_node_ids)\n",
        "\n",
        "# Step 2: Fetch their labels\n",
        "labels = node_labels[source_node_ids].cpu().numpy()\n",
        "\n",
        "# Step 3: Fetch the attention weights for edges (attention is logged during GAT's forward pass above)\n",
        "# attention shape = (N, NH, 1) -> (N, NH) - we just squeeze the last dim it's superfluous\n",
        "all_attention_weights = gat.gat_net[gat_layer_id].attention_weights.squeeze(dim=-1)\n",
        "print(src_nodes_indices)\n",
        "attention_weights = all_attention_weights[src_nodes_indices, head_to_visualize].cpu().numpy()\n",
        "# PPI's attention pattern is much less uniform than Cora's\n",
        "print(f'Max attention weight = {np.max(attention_weights)} and min = {np.min(attention_weights)}')\n",
        "attention_weights /= np.max(attention_weights)  # rescale the biggest weight to 1 for nicer plotting\n",
        "\n",
        "# Build up the neighborhood graph whose attention we want to visualize\n",
        "# igraph constraint - it works with contiguous range of ids so we map e.g. node 497 to 0, 12 to 1, etc.\n",
        "id_to_igraph_id = dict(zip(source_node_ids, range(len(source_node_ids))))\n",
        "ig_graph = ig.Graph()\n",
        "ig_graph.add_vertices(size_of_neighborhood)\n",
        "ig_graph.add_edges([(id_to_igraph_id[neighbor], id_to_igraph_id[target_node_id]) for neighbor in source_node_ids])\n",
        "\n",
        "# Prepare the visualization settings dictionary and plot\n",
        "visual_style = {\n",
        "    \"edge_width\": attention_weights,  # make edges as thick as the corresponding attention weight\n",
        "    \"layout\": ig_graph.layout_reingold_tilford_circular()  # layout for tree-like graphs\n",
        "}\n",
        "\n",
        "ig.plot(ig_graph, **visual_style)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "royal-corruption",
      "metadata": {
        "id": "royal-corruption"
      },
      "source": [
        "Beautiful! 🎉😍\n",
        "\n",
        "Compared to Cora the attention patterns here are not constant!\n",
        "\n",
        "There is one more way to understand that GAT is learning interesting attention patterns, and that brings us to entropy histograms!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "introductory-source",
      "metadata": {
        "id": "introductory-source"
      },
      "source": [
        "# Visualizing entropy histograms 📊\n",
        "\n",
        "So, I hear you say, wait `entropy`, what? How did [Claude Shannon](http://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf) find his way in?\n",
        "\n",
        "Well it's not that hard. The attention coefficients sum up to 1 - they form a probability distribution. Where there is a probability distribution you can calculate the entropy. And the entropy quantifies the amount of information in a distribution (for my uber geeks - it's an expected value of self-information 🤓).\n",
        "\n",
        "Check out this [amazing video](https://www.youtube.com/watch?v=ErfnhcEV1O8) if you're not familiar with the concept of entropy, but actually you don't need to understand the theory of entropy so much in order to understand why we're doing this.\n",
        "\n",
        "The main idea is the following:\n",
        "\n",
        "If we have a **\"hypothetical\" GAT** that has a const attention over every node's neighborhood (i.e. **all distributions are uniform**), and we calculate the entropy (whatever that may be) of each and every neighborhood, and we make a histogram out of those numbers - **how different are the histograms** coming from it compared to the GAT we just trained?\n",
        "\n",
        "If the answer is they completely overlap, well that means our GAT has got uniform attention patterns. The smaller the overlap the less uniform the distributions are. We don't care about the information, per se, we care about how much the histograms **match**.\n",
        "\n",
        "Helpfully that brings some clarity into your mind. With that out of the way let's define a couple of functions we'll need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "technological-expert",
      "metadata": {
        "id": "technological-expert"
      },
      "outputs": [],
      "source": [
        "# Draws (but doesn't yet plot) the entropy histogram. If you're confused to why do we have entropy here all of a sudden\n",
        "# bear with me you'll soon understand. Basically it helps us quantify the usefulness of GAT's learned attention pattern.\n",
        "def draw_entropy_histogram(entropy_array, title, color='blue', uniform_distribution=False, num_bins=30):\n",
        "    max_value = np.max(entropy_array)\n",
        "    bar_width = (max_value / num_bins) * (1.0 if uniform_distribution else 0.75)\n",
        "    histogram_values, histogram_bins = np.histogram(entropy_array, bins=num_bins, range=(0.0, max_value))\n",
        "\n",
        "    plt.bar(histogram_bins[:num_bins], histogram_values[:num_bins], width=bar_width, color=color)\n",
        "    plt.xlabel(f'entropy bins')\n",
        "    plt.ylabel(f'# of node neighborhoods')\n",
        "    plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adjacent-conversation",
      "metadata": {
        "id": "adjacent-conversation"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import entropy\n",
        "\n",
        "\n",
        "# Let's define an enum as a clean way to pick between different visualization options\n",
        "class VisualizationType(enum.Enum):\n",
        "    ATTENTION = 0,\n",
        "    ENTROPY = 1\n",
        "\n",
        "\n",
        "def visualize_entropy_histograms(model_name=r'gat_PPI_000000.pth', dataset_name=DatasetType.PPI.name):\n",
        "    # Fetch the data we'll need to create visualizations\n",
        "    all_nodes_unnormalized_scores, edge_index, node_labels, gat = gat_forward_pass(model_name, dataset_name)\n",
        "\n",
        "    # We want our local probability distributions (attention weights over the neighborhoods) to be\n",
        "    # non-uniform because that means that GAT is learning a useful pattern. Entropy histograms help us visualize\n",
        "    # how different those neighborhood distributions are from the uniform distribution (constant attention).\n",
        "    # If the GAT is learning const attention we could well be using GCN or some even simpler models.\n",
        "    num_heads_per_layer = [layer.num_of_heads for layer in gat.gat_net]\n",
        "    num_layers = len(num_heads_per_layer)\n",
        "    num_of_nodes = len(node_features)\n",
        "\n",
        "    target_node_ids = edge_index[1].cpu().numpy()\n",
        "\n",
        "    # For every GAT layer and for every GAT attention head plot the entropy histogram\n",
        "    for layer_id in range(num_layers):\n",
        "        # Fetch the attention weights for edges (attention is logged during GAT's forward pass above)\n",
        "        # attention shape = (N, NH, 1) -> (N, NH) - we just squeeze the last dim it's superfluous\n",
        "        all_attention_weights = gat.gat_net[layer_id].attention_weights.squeeze(dim=-1).cpu().numpy()\n",
        "\n",
        "        # tmp fix for PPI there are some numerical problems and so most of attention coefficients are 0\n",
        "        # and thus we can't plot entropy histograms\n",
        "        if dataset_name == DatasetType.PPI.name and layer_id > 0:\n",
        "            print(f'Entropy histograms for {dataset_name} are available only for the first layer.')\n",
        "            break\n",
        "\n",
        "        for head_id in range(num_heads_per_layer[layer_id]):\n",
        "            uniform_dist_entropy_list = []  # save the ideal uniform histogram as the reference\n",
        "            neighborhood_entropy_list = []\n",
        "\n",
        "            # This can also be done much more efficiently via scatter_add_ (no for loops)\n",
        "            # pseudo: out.scatter_add_(node_dim, -all_attention_weights * log(all_attention_weights), target_index)\n",
        "            for target_node_id in range(num_of_nodes):  # find every the neighborhood for every node in the graph\n",
        "                # These attention weights sum up to 1 by GAT design so we can treat it as a probability distribution\n",
        "                neigborhood_attention = all_attention_weights[target_node_ids == target_node_id].flatten()\n",
        "                # Reference uniform distribution of the same length\n",
        "                ideal_uniform_attention = np.ones(len(neigborhood_attention))/len(neigborhood_attention)\n",
        "\n",
        "                # Calculate the entropy, check out this video if you're not familiar with the concept:\n",
        "                # https://www.youtube.com/watch?v=ErfnhcEV1O8 (Aurélien Géron)\n",
        "                neighborhood_entropy_list.append(entropy(neigborhood_attention, base=2))\n",
        "                uniform_dist_entropy_list.append(entropy(ideal_uniform_attention, base=2))\n",
        "\n",
        "            title = f'{dataset_name} entropy histogram layer={layer_id}, attention head={head_id}'\n",
        "            draw_entropy_histogram(uniform_dist_entropy_list, title, color='orange', uniform_distribution=True)\n",
        "            draw_entropy_histogram(neighborhood_entropy_list, title, color='dodgerblue')\n",
        "\n",
        "            fig = plt.gcf()  # get current figure\n",
        "            plt.show()\n",
        "            fig.savefig(os.path.join(DATA_DIR_PATH, f'layer_{layer_id}_head_{head_id}.jpg'))\n",
        "            plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "outstanding-picture",
      "metadata": {
        "id": "outstanding-picture"
      },
      "source": [
        "Finally, let's run it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "color-ground",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "color-ground",
        "outputId": "fd77c5cd-beab-4168-feaf-efd4779e911d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading test graph 23 to CPU. It has 3224 nodes and 103872 edges.\n",
            "Loading test graph 24 to CPU. It has 2300 nodes and 63628 edges.\n",
            "\n",
            "***** Model training metadata: *****\n",
            "commit_hash: ad028f5d4bdb533020a73c6ffcacfb2fd9767539\n",
            "dataset_name: PPI\n",
            "num_of_epochs: 200\n",
            "test_perf: 0.9779919847816116\n",
            "num_of_layers: 3\n",
            "num_heads_per_layer: [4, 4, 6]\n",
            "num_features_per_layer: [50, 256, 256, 121]\n",
            "add_skip_connection: True\n",
            "bias: True\n",
            "dropout: 0.0\n",
            "layer_type: IMP3\n",
            "*************************************\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debgcVbnv8e+PMAhhCJCQAxmZRBFkMAdQ4BwO4BWU6SLKLCDKdYJwUBC5eoheUDxHgSCKIihhngQJ4AxEVERMmMMgMRKSEEiAECaZwnv/qLWLzk7v7to7XV17d36f5+lnV62qrnqrq3a/vapWrVJEYGZmBrBC1QGYmVn/4aRgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1KwQiQ9Lmn3HqbtLOnRdsfUbpKmSPpU1XEsLySdIumCEpZ7pKQ/tnq5PazrIkmntWNdreKkkKQvvX9KeknS02lnrp6mTZH0apr2jKTrJK2fppWy0yXtImlOq5dbhoj4Q0Rs1mw+SRMkXdqOmJZXkg6RNEvSy5J+LmmdFi13qYQoKSRt0qLlL3W8R8Q3I2K5TMKSdpP0iKRXJN0maUy71u2ksKS9I2J1YFtgHPDVmmlfSNPeCQwBzqogviVIWrHqGPqLTv0serNdkt4D/Ag4HBgOvAL8oKTQrCSShgLXAV8D1gGmAle1a/1OCnVExFzgl8AWdaY9B/ys3rR6JO0l6V5Jz0u6Q9J7a6Y9LulLku6XtEjSVZLeIWlwWv8GqXbykqQN0i/tayVdKukF4MhUPlnSc5JmSPp0zfK75r9K0ouS7pa0VZp2oqSfdYv1HEkTG2zO1t1jTe9b4leepC9LmpvW+Wj61bMHcApwYNqe+9K8jeJfVdIkSQslPSzppG7reTyt637gZUkrSjpZ0t/Tuh+S9L9r5j9S0p8knZX2x0xJH0jlsyXNl3REwf26saRbJT2bao+XSRpS5LOVtJakCyXNS5/TaZIG1YnxWWBCkXiSQ4EbI+L2iHiJ7Etlf0lrFNietSXdJGlB+rxvkjQyTTsd2Bk4N+27cyXdnt56Xyo7MM3b6uP90pr37yNpelr2FEnvbrbsJtv8nbSt/5C0Z015o/3T435P07dR9n/2oqSrgIYx9GB/YHpEXBMRr5IdA1tJelcfltV7EeFX1tXH48DuaXgUMB34f2l8CvCpNDwUuBW4JI1fBJzWwzK3AeYD2wODgCPSelapWeddwAZkvwgeBj6Tpu0CzOm2vAnAG8B+ZAl9VeB2sl+D7wC2BhYAu3ab/wBgJeBLwD/S8PrAy8CQNO+KKdb3Nfh8msYKbAbMBjZI42OBjWviubTbchvFfwbwe2BtYCRwf+1nkmK6N+2vVVPZx1KMKwAHpm1cP007EngTOCrtj9OAJ4DvA6sA/wt4EVi9h8+g9jjYBPhget+wtB1np2kNP1vgerJf9IOB9dLn+n+6xXhset+qwE7A8w1eO6X33gB8uVvML/W0T7vNty7wUWA1YA3gGuDn9ba9piyATUo+3i9Nw+9Mn+kHyY7fk4AZwMrNll1nW48k+7/4dIrzs8CTgArsn0b7fWVgFvCfKcYD0npOS9NHN9mPh6T5JgLndYv5QeCjbfkubMdKBsIrHVQvpZ0zi+yLquuLZgpZVfx5YC5wGTAsTbuInpPCeaTEUlP2KPDvNes8rGbafwM/bPJPcnvN+ChgMbBGTdm3gItq5r+zZtoKwDxg5zT+S+DTaXgv4KEmn0/TWNM/zXxgd2ClOvFf2ov4ZwIfqpn2KZZOCp9ssl/vBfZNw0cCj9VM25Lsi214TdmzwNY9LGsK3b4Ya6btB9xTM173syU7rfNa17GVyg4GbquJ8Yk+HsO30O2LMB2vu/RhWVsDCxttO0snhTKO966k8DXg6m7Hcr5tjZZdZ9uOBGbUjK+WtuVfmu2fRvsd+Ddqkksqu4Mevh8afPYXAmd0K/sTcGRfjovevjryPOwy2C8iftfDtOMiorctIcYAR0g6tqZsZbJfM12eqhl+pdu0embXDG8APBcRL9aUzSK7HrLU/BHxVjr90rWOSWS/kn4MHAZc0mTdTWONiBmSjif7h36PpF8DJ0TEk3WW1yz+DVhye2uH65ZJ+gRwAlkNBWB1stpdl6drhv+ZYu5etnqd9SxB0nCyX3Q7k/2yXgFYWDNLT5/tGLJfkfMkdc27As23s4iXgDW7la1JVvtpSNJqZNfJ9iCrmQGsIWlQRCwuuP4yjvcuG5AdG0B+LM8GRvRx2fm8EfFK2herk9Uyetw/Tfb7BsDcSN/iySx6r8/7sRV8TaFcs4HTI2JIzWu1iLiiwHt76r62tvxJYJ1u54xHk/2C6jKqa0DSCmSnYbq+oH8OvFfSFmS/Zi8rEFdTEXF5ROxE9iURwLfrxF4k/nkp3i6jWFq+TGUtNH4MfAFYNyKGkFW7Ved9y+qbad1bRsSaZF/8tevp6bOdTfZLdGjNMbFmRLyn3jal7dq55lx7vdfOadbpwFY179uI7DTH3wpszxfJTv1tn7bn37oWUy+mHpRxvHd5kux4yoLKvrFHseSx3grN9k+j/T4PGKGabEJ2PHfFPLrJfjw0zdp9Pw4GNk7lpXNSKNePgc9I2l6ZwZI+UuTCH9kv2nUlrdXTDBExm6x6+q10we69wNFAbbPP90naX1krluPJDvg70/tfBa4FLgfuiogn+rKRtSRtJmlXSasAr5L98n6rZpvGpuRUJP6rga+ki6AjyL7sGxlM9g+7IMVyFAUbBPTBGmS/6Bal2E6sndjTZxsR84DfAN+VtKakFdLFy3/vaUWRNfldvcHrD2nWy4C9UxIZDHwDuK6rJqas+fRFDbbnn8Dzypqxntpt+tPARk3KyjzerwY+oqzRwkpkSew1suOnZQrsn0b7/c9k14OOk7SSpP2B7WqW/UST/dj1w+F6YAtJH00Xy/8LuD8iHmnltvbESaFEETGV7GLWuWRVzBlk5zOLvPcR4ApgZmpt0VNV+GCyUyVPkh1Mp3Y7BXYD2QXXhWRNFfePiDdqpk8iO7fe7NRRUauQXSB+hqyKvh7wlTTtmvT3WUl3F4j/G8AcsovjvyP7kn2tpxVHxEPAd8n+OZ8m264/tWKj6vg6WdPlRcDNZE0Iu+vps/0E2WmVh8j2y7VkF6eXSURMBz5Dlhzmk32Bfa5mllH0/HmcTXZR+xmyHw2/6jZ9InBAaq1zTiqbAExKx+fHyzzeI+JRsl/l30sx7k3WhPz1IsvvpUb7p8f9nmLZn2ybnyP7v6t3XDQUEQvILvqfnta/PXBQn7akD7qutlsHkjSB7ELgYQ3mGQ08AvxLRLzQrtj6QtJngYMiosdf1f1Jf/psJa0M3Ae8t9uPArMluKawHEuncU4Arqz6S6seSetL2jFV4TcjO2VwfdVxFdHfPtuIeD0i3u2EYM249dFyKp1zfpqsdcQeFYfTk5XJ2otvSNYc+EoGwB26A+SzNavLp4/MzCzn00dmZpYb0KePhg4dGmPHjq06DDOzAWXatGnPRMSwetMGdFIYO3YsU6dOrToMM7MBRVKPd1r79JGZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlBvQdzTZwjZm4dNms8e2Pw8yW5JqCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHKlJwVJgyTdI+mmNL6hpL9ImiHpKkkrp/JV0viMNH1s2bGZmdmS2lFTGA88XDP+beCsiNgEWAgcncqPBham8rPSfGZm1kYrlrlwSSOBjwCnAydIErArcEiaZRIwATgP2DcNA1wLnCtJERFlxmj9z5iJ9ctnjW9vHGbLo7JrCmcDJwFvpfF1gecj4s00PgcYkYZHALMB0vRFaf4lSDpG0lRJUxcsWFBm7GZmy53SkoKkvYD5ETGtlcuNiPMjYlxEjBs2bFgrF21mttwr8/TRjsA+kj4MvANYE5gIDJG0YqoNjATmpvnnAqOAOZJWBNYCni0xPjMz66a0mkJEfCUiRkbEWOAg4NaIOBS4DTggzXYEcEManpzGSdNv9fUEM7P2quI+hS+TXXSeQXbN4MJUfiGwbio/ATi5gtjMzJZrpbY+6hIRU4ApaXgmsF2deV4FPtaOeMzMrD7f0WxmZjknBTMzyzkpmJlZzknBzMxyvUoKklaQtGZZwZiZWbWaJgVJl0taU9Jg4EHgIUknlh+amZm1W5GawuYR8QKwH/BLYEPg8FKjMjOzShRJCitJWoksKUyOiDcA32lsZtaBiiSFHwGPA4OB2yWNAV4oMygzM6tG0zuaI+Ic4JyaolmS/qO8kMzMrCo9JgVJJzR575ktjsXMzCrWqKawRvq7GfCvZL2YAuwN3FVmUGZmVo0ek0JEfB1A0u3AthHxYhqfANzclujMuvGjOs3KVeRC83Dg9Zrx11OZmZl1mCJdZ18M3CXpekDAvsBFZQZlZmbVKNL66HRJvwR2Jrs/4aiIuKf0yMzMrO2KPmRnMfAWWVJ4q7xwzMysSkX6PhoPXAYMBdYDLpV0bNmBmZlZ+xWpKRwNbB8RLwNI+jbwZ+B7ZQZmZmbtV6T1kchOH3VZnMrMzKzDFKkp/BT4S7fWRxeWGpV1hHr3FPh+ArP+rUjrozMlTQF2wq2PzMw6Wm9aHwVufWT9nGsnZsvGrY/MzCzn1kdmZpZz6yMzM8v1tvURZI/ldOsjM7MOVLT10e+BHVORWx+ZmXWooq2P7gXmdc0vaXREPFFaVGZmVommSSG1NDoVeJq3rycE8N5yQzMzs3YrUlMYD2wWEc+WHYyZmVWrSOuj2cCisgMxM7Pq9VhTkHRCGpwJTJF0M/Ba1/SIOLPk2MzMrM0anT5aI/2dBTwBrJxeZmbWoXpMChHxdUmDgIsj4tA2xmRmZhVpeE0hIhYDYyS5hmBmthwo0vpoJvAnSZOBl7sKm11TkPQO4HZglbSeayPiVEkbAlcC6wLTgMMj4nVJqwAXA+8DngUOjIjHe79JZmbWV0VaH/0duCnNu0bNq5nXgF0jYitga2APSTsA3wbOiohNgIVkHe6R/i5M5Wel+czMrI2KdHPxdQBJq6fxl4osOCIC6Jp3pfQKYFfgkFQ+CZgAnEf2RLcJqfxa4FxJSssxM7M2KPI8hS0k3QNMB6ZLmibpPUUWLmmQpHuB+cBvyWodz0fEm2mWOcCINDyC7J4I0vRFZKeYui/zGElTJU1dsGBBkTDMzKygIqePzgdOiIgxETEG+CLw4yILj4jFEbE1MBLYDnhXnyN9e5nnR8S4iBg3bNiwZV2cmZnVKJIUBkfEbV0jETEFGNyblUTE88BtwPuBIZK6TluNBOam4bnAKIA0fS2yC85mZtYmRZLCTElfkzQ2vb5K1iKpIUnDJA1Jw6sCHwQeJksOB6TZjgBuSMOT0zhp+q2+nmBm1l5FmqR+Evg6cF0a/0Mqa2Z9YFK6AW4F4OqIuEnSQ8CVkk4D7uHtB/ZcCFwiaQbwHHBQ8c0wM7NWKNL6aCFwnKS1gLci4sUiC46I+4Ft6pTPJLu+0L38VeBjRZZt1u9d3osn1h7iCrH1H0VaH/2rpAeA+4AHJN0n6X3lh2ZmZu1W5PTRhcDnIuIPAJJ2Intusx+yY2bWYYpcaF7clRAAIuKPwJsN5jczswGq0fMUtk2Dv5f0I+AKsjuSDwSmlB+amS2h6HUKX6OwZdDo9NF3u42fWjPso87MrAM1ep7Cf7QzEDMzq17TC82pS+uPAmNr54+Ib5QXlpmZVaFI66MbyDqnm0bNM5rNrJ/ytQdbBkWSwsiI2KP0SMzMrHJFmqTeIWnL0iMxM7PKNWqS+gBZK6MVgaMkzSQ7fSSyZ+j45jUzsw7T6PTRXm2LwgasMROXLps1vv1xmFlrNGqSOgtA0jp1JhfqFM/MzAaWItcU7gYWAH8DHkvDj0u62x3jmZl1liJJ4bfAhyNiaESsC+wJ3AR8DvhBmcGZmVl7FUkKO0TEr7tGIuI3wPsj4k5gldIiMzOztityn8I8SV8GrkzjBwJPpyeqvVVaZGZm1nZFagqHACOBn6fX6FQ2CPh4eaGZmVm7FXkc5zPAsT1MntHacMzMrEqNbl47OyKOl3QjdbrKjoh9So3MzMzarlFN4ZL09zvtCMTMzKrX6Oa1aenv7yWtCoyOiEfbFpmZmbVd0wvNkvYG7gV+lca3ljS57MDMzKz9irQ+mgBsBzwPEBH3AhuWGJOZmVWkSFJ4IyIWdSvz0znMzDpQkZvXpks6BBgkaVPgOOCOcsMyM7MqFKkpHAu8h+xZClcALwDHlxmUmZlVo8jNa68A/ze9zKzVij5T2awNmiYFSe8EvgSMrZ0/InYtLywzM6tCkWsK1wA/BC4AFpcbjpmZValIUngzIs4rPRIzM6tckQvNN0r6nKT1Ja3T9So9MjMza7siNYUj0t8Ta8oC2Kj14ZiVoMiF3EN8640ZFGt95LuXzTpR0VZPTpjLlSKnj8zMbDnhpGBmZrnSkoKkUZJuk/SQpOmSxqfydST9VtJj6e/aqVySzpE0Q9L9krYtKzYzM6uvSNfZknSYpP9K46MlbVdg2W8CX4yIzYEdgM9L2hw4GbglIjYFbknjAHsCm6bXMYCbwZqZtVmRmsIPgPcDB6fxF4HvN3tTRMyLiLvT8IvAw8AIYF9gUpptErBfGt4XuDgydwJDJK1fdEPMzGzZFWmSun1EbCvpHoCIWChp5d6sRNJYYBvgL8DwiJiXJj0FDE/DI4DZNW+bk8rmYVY2t8QxA4olhTckDSI9Q0HSMOCtoiuQtDrwM+D4iHhBevufLyJCUq/+yyQdQ3Z6idGjR/fmrbacG7Ng6UNt1jB3RmdWq8jpo3OA64H1JJ0O/BH4ZpGFS1qJLCFcFhHXpeKnu04Lpb/zU/lcYFTN20emsiVExPkRMS4ixg0bNqxIGGZmVlDTpBARlwEnAd8iO5WzX0Rc0+x9yqoEFwIPR8SZNZMm8/Zd0kcAN9SUfyJd2N4BWFRzmsnMzNqgx9NH3fo3mk/2gJ18WkQ812TZOwKHAw9IujeVnQKcAVwt6WhgFvDxNO0XwIeBGcArwFG92A4zM2uBRtcUppFdRxAwGliYhocATwANu7+IiD+m+evZrc78AXy+echmZlaWHk8fRcSGEbER8Dtg74gYGhHrAnsBv2lXgGZm1j5FLjTvEBG/6BqJiF8CHygvJDMzq0qRJqlPSvoqcGkaPxR4sryQzMysKkVqCgcDw8iapV4PrMfbdzebmVkHKfI8heeA8ZLWyEbjpfLDMmuvwje2Fb3z2WyAKtIh3papi4sHgemSpknaovzQzMys3YqcPvoRcEJEjImIMcAXgfPLDcvMzKpQJCkMjojbukYiYgowuLSIzMysMkVaH82U9DXgkjR+GDCzvJDMzKwqRWoKnyRrfXRdeg1LZWZm1mGKtD5aCBzXhljMzKxiTZOCpHcCXwLG1s4fEbuWF5b1J2MmLl02a3z74zCz8hW5pnAN8EPgAmBxueGYmVmViiSFNyPivNIjMTOzyhW50HyjpM9JWl/SOl2v0iMzM7O2K1JT6HpK2ok1ZQFs1PpwzMysSkVaHzV8mI6ZmXWOIjUFM1uetboTwEOW7nzQ+o8i1xTMzGw50WNSkLRj+rtK+8IxM7MqNaopnJP+/rkdgdhy4nL1fDrCzyowq1yjawpvSDofGCHpnO4TI8JdX5iZdZhGSWEvYHfgQ8C09oRjZmZV6jEpRMQzwJWSHo6I+9oYk5mZVaRI66NnJV0vaX56/UzSyNIjMzOztiuSFH4KTAY2SK8bU5lZ/9HoAraZFVYkKawXET+NiDfT6yKyB+2YmVmHKZIUnpF0mKRB6XUY8GzZgZmZWfsVfRznx4GngHnAAcBRZQZlZmbVKNIh3ixgnzbEYmZmFXPfR2ZmlnNSMDOznLvOtr67XGTPW6pXTv1pZr1pOuxuttuuaU1B0ldrht1jqplZB2vUdfaXJb2frLVRF/eYambWwRqdPnoE+BiwkaQ/pPF1JW0WEY+2JTozM2urRqePngdOAWYAuwATU/nJku4oOS4zM6tAo6TwIeBmYGPgTGB74OWIOCoiPtBswZJ+kjrQe7CmbB1Jv5X0WPq7diqXpHMkzZB0v6Rtl22zzMysL3pMChFxSkTsBjwOXAIMAoZJ+qOkGwss+yJgj25lJwO3RMSmwC1pHGBPYNP0OgY4rxfbYGZmLVLkPoVfR8TUiDgfmBMRO1Ggm4uIuB14rlvxvsCkNDwJ2K+m/OLI3AkMkbR+oS0wM7OWaZoUIuKkmtEjU9kzfVzf8IiYl4afAoan4RHA7Jr55qSypUg6RtJUSVMXLFjQxzCs32rUht1dY5uVrld3NLfyCWwREfTh7qaIOD8ixkXEuGHD3IO3mVkrtbubi6e7Tgulv/NT+VxgVM18I1OZmZm1UbuTwmTgiDR8BHBDTfknUiukHYBFNaeZzMysTUrr+0jSFWT3NwyVNAc4FTgDuFrS0cAssuc0APwC+DDZPRGv4Oc1mJlVorSkEBEH9zBptzrzBvD5smIxWxZjFtS/9DVrmC98W+dx19lmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5P47TzPqvol2b+LGdLeOkYGYDn5NHyzgpGGMm1i+fNb69cZhZ9XxNwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOfWR2bLwD2oWqdxTcHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyvqPZzJYffhhPU64pmJlZzknBzMxyPn1kVqJ6Hea5szzrz1xTMDOznGsKZhVxLcL6IycFM7PuluNWSj59ZGZmOScFMzPL+fRRJ0hV3abnqDuwqmtmreWagpmZ5ZwUzMws59NHy4kxCwImLl0+a3z7YzGz/qtfJQVJe5B9dQ0CLoiIMyoOyawSja4P1ZtWO93aqGjT1d6o+Npfv0kKkgYB3wc+CMwB/ippckQ8VG1kZmZtVPE9Ev0mKQDbATMiYiaApCuBfQEnBbOCGtUilqWG0duai2stA5ci+kczRUkHAHtExKfS+OHA9hHxhW7zHQMck0Y3Ax5tYRhDgWdauLz+xNs28HTqdkHnbttA2a4xETGs3oT+VFMoJCLOB84vY9mSpkbEuDKWXTVv28DTqdsFnbttnbBd/alJ6lxgVM34yFRmZmZt0p+Swl+BTSVtKGll4CBgcsUxmZktV/rN6aOIeFPSF4BfkzVJ/UlETG9zGKWcluonvG0DT6duF3Tutg347eo3F5rNzKx6/en0kZmZVcxJwczMck4KiaQ9JD0qaYakk6uOp1UkjZJ0m6SHJE2X1FG9HUkaJOkeSTdVHUsrSRoi6VpJj0h6WNL7q46pFST9ZzoOH5R0haR3VB1TX0n6iaT5kh6sKVtH0m8lPZb+rl1ljH3hpMASXWzsCWwOHCxp82qjapk3gS9GxObADsDnO2jbAMYDD1cdRAkmAr+KiHcBW9EB2yhpBHAcMC4itiBrUHJQtVEtk4uAPbqVnQzcEhGbArek8QHFSSGTd7EREa8DXV1sDHgRMS8i7k7DL5J9uYyoNqrWkDQS+AhwQdWxtJKktYB/Ay4EiIjXI+L5aqNqmRWBVSWtCKwGPFlxPH0WEbcDz3Ur3heYlIYnAfu1NagWcFLIjABm14zPoUO+OGtJGgtsA/yl2kha5mzgJOCtqgNpsQ2BBcBP06mxCyQNrjqoZRURc4HvAE8A84BFEfGbaqNqueERMS8NPwUMrzKYvnBSWE5IWh34GXB8RLxQdTzLStJewPyImFZ1LCVYEdgWOC8itgFeZgCehugunV/flyzpbQAMlnRYtVGVJ7L2/gOuzb+TQqaju9iQtBJZQrgsIq6rOp4W2RHYR9LjZKf7dpV0abUhtcwcYE5EdNXoriVLEgPd7sA/ImJBRLwBXAd8oOKYWu1pSesDpL/zK46n15wUMh3bxYYkkZ2bfjgizqw6nlaJiK9ExMiIGEu2v26NiI741RkRTwGzJW2WinajM7qQfwLYQdJq6bjcjQ64gN7NZOCINHwEcEOFsfRJv+nmokr9pIuNsuwIHA48IOneVHZKRPyiwpisuWOBy9KPlJnAURXHs8wi4i+SrgXuJmsVdw8DuFsISVcAuwBDJc0BTgXOAK6WdDQwC/h4dRH2jbu5MDOznE8fmZlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzGpI2q/dHQZKukjSAXXKx0k6p52xmDkpmC1pP7KecpeSOnFrm4iYGhHHtXOdZk4K1tEkHSbpLkn3SvpR6iYdSS9JOl3SfZLulDRc0geAfYD/SfNvLGmKpLMlTQXGS9otdVL3QOpPf5W0vMcl/Xcqv0vSJpLWkPSP1M0IktasHe9md0lTJf0t9euEpF26nhMhaUJa3xRJMyUdl8oHS7o5bceDkg4s/1O1TuakYB1L0ruBA4EdI2JrYDFwaJo8GLgzIrYCbgc+HRF3kHVTcGJEbB0Rf0/zrhwR48ieuXERcGBEbEnWI8Bna1a5KJWfC5yduiqfQta9N2TdcVyX+v3pbixZF+4fAX7Yw8Nn3gV8KM13akouewBPRsRW6RkFvyr8AZnV4aRgnWw34H3AX1MXH7sBG6VprwNdT2ubRval3JOr0t/NyDp0+1san0T23IMuV9T87XpS2gW83UXFUcBPe1jH1RHxVkQ8RtatxbvqzHNzRLwWEc+QdbQ2HHgA+KCkb0vaOSIWNdgOs6bc95F1MgGTIuIrdaa9EW/38bKYxv8LLxdcX3Qfjog/SRoraRdgUEQ8WPedS3exXK//mddqhhcDK0bE3yRtC3wYOE3SLRHxjYLxmi3FNQXrZLcAB0haD/Ln545p8p4XgTV6mPYoMFbSJmn8cOD3NdMPrPn755ryi4HL6bmWAPAxSStI2pisNvNokzgBkLQB8EpEXAr8D53RxbZVyDUF61gR8ZCkrwK/kbQC8AbwebLeK3tyJfDjdCF3iXj0d40AAACNSURBVGaiEfGqpKOAa1JLpL8CP6yZZW1J95P9oj+4pvwy4DTePr1UzxPAXcCawGfSuops5pZkF8bfStv32SbzmzXkXlLNWiA97GdcOt/ffdoBwL4RcXjbAzPrJdcUzEok6XvAnmTn/M36PdcUzMws5wvNZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmuf8PsHoQd6k8j/wAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entropy histograms for PPI are available only for the first layer.\n"
          ]
        }
      ],
      "source": [
        "visualize_entropy_histograms(\n",
        "        model_name,\n",
        "        dataset_name,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "united-interest",
      "metadata": {
        "id": "united-interest"
      },
      "source": [
        "And voilà, the light blue histograms (trained GAT) are skewed compared to the orange one (uniform attention GAT). And additionally, they are skewed to the left which we could have expected since the **uniform distributions have the highest entropy.**\n",
        "\n",
        "If the previous visualization with edge thickness plotted didn't convince you I'm sure that entropy will! (*laughs in kilo bits per cringe*)\n",
        "\n",
        "The idea for this visualization came from [this blog post](https://www.dgl.ai/blog/2019/02/17/gat.html) recommended to me by Petar Veličković.\n",
        "\n",
        "---\n",
        "\n",
        "Phew!!! That was a mouthful! If you stayed with me until here, **congrats!** (achievement unlocked - GAT master 😍)\n",
        "\n",
        "Take your time to analyze this notebook. This is not a toy project, it took me ~3 weeks to finish it <br/> \n",
        "so don't expect to understand everything in 30 minutes unless you're really familiar with most of the concepts mentioned here.\n",
        "\n",
        "And last but not least!\n",
        "\n",
        "# Connect with me\n",
        "\n",
        "I share lots of useful (I hope so at least!) content on LinkedIn, Twitter, YouTube and Medium. <br/>\n",
        "So feel free to connect with me there:\n",
        "1. My [LinkedIn](https://www.linkedin.com/in/aleksagordic) and [Twitter](https://twitter.com/gordic_aleksa) profiles\n",
        "2. My YouTube channel - [The AI Epiphany](https://www.youtube.com/c/TheAiEpiphany)\n",
        "3. My [Medium](https://gordicaleksa.medium.com/) profile\n",
        "\n",
        "Also do drop me a message if you found this useful or if you think I could've done something better! <br/>\n",
        "I always like getting some feedback on the work I do.\n",
        "\n",
        "If you notice some bugs/errors feel free to **open up an issue** or even **submit a pull request**.\n",
        "\n",
        "# Additional resources\n",
        "\n",
        "If you're interested in learning more about GNNs there are many awesome resources out there.\n",
        "\n",
        "* Check out [Sergey Ivanov's newsletter](https://graphml.substack.com/p/issue-1-introduction-pac-isometry-over-smoothing-and-evolution-of-the-field-265283)\n",
        "* [Michael Bronstein's](https://medium.com/@michael.bronstein) blog posts\n",
        "\n",
        "And of course watch my videos:\n",
        "* [My overview of the GCN paper](https://www.youtube.com/watch?v=VyIOfIglrUM)\n",
        "* [My overview of the GraphSAGE paper](https://www.youtube.com/watch?v=vinQCnizqDA)\n",
        "* [My overview of the PinSage paper](https://www.youtube.com/watch?v=ed0NJdqwEyg)\n",
        "* [My overview of Temporal Graph Networks (TGN)](https://www.youtube.com/watch?v=0tw66aTfWaI)\n",
        "\n",
        "Also, follow GNN experts on Twitter. That's a good strategy to stay in touch with the field. Check out the people I follow that's better than me cherry-picking some names here.\n",
        "\n",
        "*Note: I didn't do it justice by only linking Michael and Sergey - I'll probably create a video where I'll explain how I approached learning about GNNs and various different resources I leveraged.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rUJBE9CvAQvR",
      "metadata": {
        "id": "rUJBE9CvAQvR"
      },
      "outputs": [],
      "source": [
        "i = torch.tensor(0.0).cuda()\n",
        "import time\n",
        "while True:\n",
        "    i *= i\n",
        "    time.sleep(10.0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GAT SG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
